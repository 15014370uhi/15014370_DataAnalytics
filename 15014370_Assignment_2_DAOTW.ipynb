{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15014370_Assignment_2_DAOTW.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VBvdvCNpUHso",
        "Wukr1JN1Lic6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w9sEQx-NFJv"
      },
      "source": [
        "#**Introduction**\r\n",
        "\r\n",
        "In this report I will generate linear regression models and deep neural network regressor models, to help predict traffic collision numbers, and assist in the planning of emergency response and staffing for New York City."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWESYV11PFYN"
      },
      "source": [
        "# **Methodology**\r\n",
        "\r\n",
        "Using datasets previously created using data analysis techniques, I will train, test and analyse the linear and deep neural network regression models, to determine which model and choice of data, offers the best effiacy against a set of test data, retained and separated from the original datasets.  \r\n",
        "\r\n",
        "The results will be used to identify which model or models could potentially be used to successfully predict the number of traffic collisions per day; allowing optimisation of New York City's emergency response and staffing.  \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3KN3agkDK2N"
      },
      "source": [
        "# **Modelling and Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP3-bK2Ou3CE"
      },
      "source": [
        "#**1. Mean and Minimum Temperature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yTlxcDqjBJa"
      },
      "source": [
        "The first models will be created with a large collated dataset of weather and traffic collision.  Mean and minimum temperature will be used as the primary data points for these models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p-7cPGENClE"
      },
      "source": [
        "# Import pandas to allow creation of data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Create data frame from github csv file\n",
        "source_dataframe = pd.read_csv('https://raw.githubusercontent.com/15014370uhi/15014370_DataAnalytics/master/bq-collated_collision_numbers_per_day_nyc.csv', index_col=0, );"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEw-Y4JWNkh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe2eb48-1701-4717-f9d1-6e4d6ff37931"
      },
      "source": [
        "# Check that correct data is present\n",
        "print(source_dataframe) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     year  mo  da collision_date  temp  ...   min   prcp   sndp  fog  NUM_COLLISIONS\n",
            "day                                     ...                                         \n",
            "7    2012   7   1     2012-07-01  83.6  ...  66.0   0.00  999.9    0             538\n",
            "1    2012   7   2     2012-07-02  80.3  ...  66.9   0.00  999.9    0             564\n",
            "2    2012   7   3     2012-07-03  79.8  ...  63.0   0.00  999.9    0             664\n",
            "3    2012   7   4     2012-07-04  81.8  ...  68.0   0.06  999.9    0             432\n",
            "4    2012   7   5     2012-07-05  86.7  ...  70.0  99.99  999.9    0             591\n",
            "..    ...  ..  ..            ...   ...  ...   ...    ...    ...  ...             ...\n",
            "5    2020  11  13     2020-11-13  53.5  ...  52.0   1.28  999.9    1             362\n",
            "6    2020  11  14     2020-11-14  50.5  ...  46.9   0.02  999.9    0             262\n",
            "7    2020  11  15     2020-11-15  46.4  ...  32.0   0.00  999.9    0             221\n",
            "1    2020  11  16     2020-11-16  54.9  ...  50.0   0.24  999.9    1             259\n",
            "2    2020  11  17     2020-11-17  47.4  ...  41.0   0.00  999.9    0             204\n",
            "\n",
            "[3121 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4K_es7f5ZJg",
        "outputId": "9c8c8fd9-62ed-42ad-f55c-e3ab89c001f9"
      },
      "source": [
        "# Find the total length of data rows\r\n",
        "totalNumberOfRows = len(source_dataframe);\r\n",
        "print(totalNumberOfRows);"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4FV9fPUOkvw"
      },
      "source": [
        "# Import numpty to improve speed of math calculations\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toa264C37zRx"
      },
      "source": [
        "# Shuffle all source data\r\n",
        "source_dataframe = source_dataframe.iloc[np.random.permutation(len(source_dataframe))]; "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjlvlCDSmjC"
      },
      "source": [
        "# Number of rows to reserve for testing\r\n",
        "number_of_test_rows = 50"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg5Sq9nwJWYB"
      },
      "source": [
        "# Store training data as (all rows - number_of_test_rows) of source data\n",
        "df_train = source_dataframe[:-number_of_test_rows];\n",
        "\n",
        "# Shuffle training data a second time\n",
        "df_train = df_train.iloc[np.random.permutation(len(df_train))]; \n",
        "\n",
        "# Store validation test data as last number_of_test_rows of rows of source data\n",
        "df_test = source_dataframe[-number_of_test_rows:];\n",
        "\n",
        "# Shuffle test data a second time\n",
        "df_test = df_test.iloc[np.random.permutation(len(df_test))];\n",
        "\n",
        "# Store only relevant columns of data for this model\n",
        "df_train = df_train.iloc[:, [4,12,16]]; \n",
        "df_test = df_test.iloc[:, [4,12,16]];\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyzUYmLF-B9B",
        "outputId": "c8175b36-0cbf-4b83-e249-fd900c0941b8"
      },
      "source": [
        "# Confirm training data is stored\r\n",
        "print(df_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     temp   min  NUM_COLLISIONS\n",
            "day                            \n",
            "1    69.9  59.0             533\n",
            "6    61.4  57.0             500\n",
            "7    54.7  46.0             303\n",
            "6    35.1  19.9             523\n",
            "5    61.7  57.0             749\n",
            "..    ...   ...             ...\n",
            "5    42.7  34.0             676\n",
            "5    63.2  55.0             738\n",
            "1    47.6  43.0             716\n",
            "4    70.2  66.9             695\n",
            "4    65.7  62.6             572\n",
            "\n",
            "[3071 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKahM2Kn8ia9",
        "outputId": "f757ee35-d06b-4909-e723-a1268742bd65"
      },
      "source": [
        "# Confirm test data rows are stored \r\n",
        "print(df_test);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     temp   min  NUM_COLLISIONS\n",
            "day                            \n",
            "6    59.9  52.0             558\n",
            "2    51.1  39.2             565\n",
            "3    49.3  39.9             679\n",
            "3    46.3  41.0             636\n",
            "4    74.1  66.0             356\n",
            "5    69.8  66.0             296\n",
            "4    63.6  57.9             249\n",
            "7    65.2  55.9             451\n",
            "2    54.8  46.9             741\n",
            "7    43.2  34.0             446\n",
            "3    69.2  64.0             660\n",
            "2    53.8  50.0             570\n",
            "1    29.0  26.6             553\n",
            "6    62.3  53.1             603\n",
            "5    70.1  48.9             760\n",
            "4    56.8  42.8             630\n",
            "7    69.0  62.1             441\n",
            "5    67.2  61.0             604\n",
            "5    69.1  66.9             652\n",
            "2    63.0  45.0             620\n",
            "4    36.5  33.1             689\n",
            "5    64.9  59.0             684\n",
            "5    53.0  48.9             617\n",
            "1    49.5  37.0             687\n",
            "3    32.2  28.0             531\n",
            "7    56.3  46.9             544\n",
            "1    67.7  61.0             602\n",
            "7    59.6  51.1             505\n",
            "3    44.7  41.0             706\n",
            "2    69.2  66.0             654\n",
            "7    70.6  66.9             574\n",
            "6    62.4  59.0             304\n",
            "2    67.2  50.0             727\n",
            "6    42.8  32.0             555\n",
            "5    53.3  50.0             723\n",
            "2    56.1  51.1             627\n",
            "6    66.9  61.0             534\n",
            "3    68.5  55.0             651\n",
            "7    39.9  37.0             500\n",
            "3    39.8  30.9             520\n",
            "4    45.7  28.9             635\n",
            "7    48.3  32.0             457\n",
            "5    31.7  28.9             600\n",
            "1    60.5  57.0             490\n",
            "5    37.6  30.9             753\n",
            "1    53.4  50.0             408\n",
            "4    62.5  53.1             616\n",
            "4    68.4  61.0             306\n",
            "5    38.4  33.1             743\n",
            "6    38.1  23.0             493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLiSb-UuJQuH"
      },
      "source": [
        "# Select Predictor columns for training and testing data to be used to predict the outcome\n",
        "\n",
        "predictors_train = df_train.iloc[:, [0,1]];\n",
        "predictors_test = df_test.iloc[:, [0,1]];"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tEMJHj7PDmM",
        "outputId": "2829789d-da3f-4c99-8516-9d6cdd416bfd"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     temp   min\n",
            "day            \n",
            "1    69.9  59.0\n",
            "6    61.4  57.0\n",
            "7    54.7  46.0\n",
            "6    35.1  19.9\n",
            "5    61.7  57.0\n",
            "..    ...   ...\n",
            "5    42.7  34.0\n",
            "5    63.2  55.0\n",
            "1    47.6  43.0\n",
            "4    70.2  66.9\n",
            "4    65.7  62.6\n",
            "\n",
            "[3071 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3HdI4bAPsM-",
        "outputId": "42645c55-6481-4868-abad-7b7be38217ff"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_test);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     temp   min\n",
            "day            \n",
            "6    59.9  52.0\n",
            "2    51.1  39.2\n",
            "3    49.3  39.9\n",
            "3    46.3  41.0\n",
            "4    74.1  66.0\n",
            "5    69.8  66.0\n",
            "4    63.6  57.9\n",
            "7    65.2  55.9\n",
            "2    54.8  46.9\n",
            "7    43.2  34.0\n",
            "3    69.2  64.0\n",
            "2    53.8  50.0\n",
            "1    29.0  26.6\n",
            "6    62.3  53.1\n",
            "5    70.1  48.9\n",
            "4    56.8  42.8\n",
            "7    69.0  62.1\n",
            "5    67.2  61.0\n",
            "5    69.1  66.9\n",
            "2    63.0  45.0\n",
            "4    36.5  33.1\n",
            "5    64.9  59.0\n",
            "5    53.0  48.9\n",
            "1    49.5  37.0\n",
            "3    32.2  28.0\n",
            "7    56.3  46.9\n",
            "1    67.7  61.0\n",
            "7    59.6  51.1\n",
            "3    44.7  41.0\n",
            "2    69.2  66.0\n",
            "7    70.6  66.9\n",
            "6    62.4  59.0\n",
            "2    67.2  50.0\n",
            "6    42.8  32.0\n",
            "5    53.3  50.0\n",
            "2    56.1  51.1\n",
            "6    66.9  61.0\n",
            "3    68.5  55.0\n",
            "7    39.9  37.0\n",
            "3    39.8  30.9\n",
            "4    45.7  28.9\n",
            "7    48.3  32.0\n",
            "5    31.7  28.9\n",
            "1    60.5  57.0\n",
            "5    37.6  30.9\n",
            "1    53.4  50.0\n",
            "4    62.5  53.1\n",
            "4    68.4  61.0\n",
            "5    38.4  33.1\n",
            "6    38.1  23.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hceMJGRGPPbl"
      },
      "source": [
        "# Select target column\n",
        "targets_train = df_train.iloc[:,2];\n",
        "\n",
        "# Select target column\n",
        "targets_test = df_test.iloc[:,2];"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGUF8PzMQGUS",
        "outputId": "874e4a9d-b1c2-422b-8669-ecff6d6490a9"
      },
      "source": [
        "print(targets_train);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day\n",
            "1    533\n",
            "6    500\n",
            "7    303\n",
            "6    523\n",
            "5    749\n",
            "    ... \n",
            "5    676\n",
            "5    738\n",
            "1    716\n",
            "4    695\n",
            "4    572\n",
            "Name: NUM_COLLISIONS, Length: 3071, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf3Pq6w1QTHI",
        "outputId": "b481fcc5-fe8d-432f-b603-a7952aa9aedc"
      },
      "source": [
        "print(targets_test);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day\n",
            "6    558\n",
            "2    565\n",
            "3    679\n",
            "3    636\n",
            "4    356\n",
            "5    296\n",
            "4    249\n",
            "7    451\n",
            "2    741\n",
            "7    446\n",
            "3    660\n",
            "2    570\n",
            "1    553\n",
            "6    603\n",
            "5    760\n",
            "4    630\n",
            "7    441\n",
            "5    604\n",
            "5    652\n",
            "2    620\n",
            "4    689\n",
            "5    684\n",
            "5    617\n",
            "1    687\n",
            "3    531\n",
            "7    544\n",
            "1    602\n",
            "7    505\n",
            "3    706\n",
            "2    654\n",
            "7    574\n",
            "6    304\n",
            "2    727\n",
            "6    555\n",
            "5    723\n",
            "2    627\n",
            "6    534\n",
            "3    651\n",
            "7    500\n",
            "3    520\n",
            "4    635\n",
            "7    457\n",
            "5    600\n",
            "1    490\n",
            "5    753\n",
            "1    408\n",
            "4    616\n",
            "4    306\n",
            "5    743\n",
            "6    493\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMxwMfGPdWJ"
      },
      "source": [
        "# Set scale value\n",
        "SCALE_NUM_COLLISIONS = 1000.0;"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbgNNZYkPkCA"
      },
      "source": [
        "# Get size of training set \n",
        "trainsize = int(len(df_train['NUM_COLLISIONS']));\n",
        "\n",
        "# Get size of test set \n",
        "testsize = int(len(df_test['NUM_COLLISIONS']));"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euT36H2ZQsEm",
        "outputId": "55dd5a8e-280e-463c-da0d-621efc459be4"
      },
      "source": [
        "print(trainsize);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UUnauybQvpg",
        "outputId": "dd582d82-0b3b-4b2c-bdb5-f3ee2ba36556"
      },
      "source": [
        "print(testsize);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpJq4_uqQraq"
      },
      "source": [
        "\r\n",
        "# Define the number of predictor column input values\r\n",
        "nppredictors = len(predictors_train.columns);\r\n",
        "\r\n",
        "# Define the number of target column output values\r\n",
        "noutputs = 1;\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVnNFN4bRVbS",
        "outputId": "6f398d8d-62d9-4158-a61f-b9b0e298be5c"
      },
      "source": [
        "print(nppredictors)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUE3HJ8HR5ro"
      },
      "source": [
        "# **1.1 Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maFRZkDkQdpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b53689c-8346-4302-e779-ee0850b96a9d"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_temp_min', ignore_errors=True)\n",
        "   \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_temp_min', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Prints log to show start of training model\n",
        "print(\"starting to train...\\n\");\n",
        "\n",
        "# Train the model using predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Check predictions based on predictor values\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply Scale value to outputs\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE using predictions and targets\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nLinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store linear regressor value\n",
        "rmse_LR = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate mean value of Number of Collisions\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Number of Collision Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2));\n",
        "print('Just using an average = {0}, has RMSE of {1}'.format(avg, rmse)); \n",
        "\n",
        "# store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "if(rmse_LR < rmse_avg): # If DNN rmse is lower than average rmse\n",
        "  print('\\nGreat! Your Linear Regression model performs better than finding average!');\n",
        "else: \n",
        "  print('\\nSorry! On this run, your model performs worse than just finding the average!');\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-22-5d40dbde9441>:18: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1b312bb38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-22-5d40dbde9441>:18: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "starting to train...\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_temp_min/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.3366867, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 79 vs previous value: 79. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 81 vs previous value: 81. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 758.816\n",
            "INFO:tensorflow:loss = 0.03110689, step = 101 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.44\n",
            "INFO:tensorflow:loss = 0.019703131, step = 201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.176\n",
            "INFO:tensorflow:loss = 0.026463617, step = 301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.669\n",
            "INFO:tensorflow:loss = 0.016906146, step = 401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.091\n",
            "INFO:tensorflow:loss = 0.016708564, step = 501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.883\n",
            "INFO:tensorflow:loss = 0.02320392, step = 601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.704\n",
            "INFO:tensorflow:loss = 0.016554223, step = 701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.208\n",
            "INFO:tensorflow:loss = 0.0161747, step = 801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.246\n",
            "INFO:tensorflow:loss = 0.014678741, step = 901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 937.344\n",
            "INFO:tensorflow:loss = 0.016699985, step = 1001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.817\n",
            "INFO:tensorflow:loss = 0.021360494, step = 1101 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.417\n",
            "INFO:tensorflow:loss = 0.06665199, step = 1201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.489\n",
            "INFO:tensorflow:loss = 0.022908516, step = 1301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.673\n",
            "INFO:tensorflow:loss = 0.020690667, step = 1401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.327\n",
            "INFO:tensorflow:loss = 0.017839307, step = 1501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.469\n",
            "INFO:tensorflow:loss = 0.024736289, step = 1601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.262\n",
            "INFO:tensorflow:loss = 0.01925693, step = 1701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.68\n",
            "INFO:tensorflow:loss = 0.089248955, step = 1801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.721\n",
            "INFO:tensorflow:loss = 0.036626883, step = 1901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.155\n",
            "INFO:tensorflow:loss = 0.3155719, step = 2001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.829\n",
            "INFO:tensorflow:loss = 0.029824022, step = 2101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1028.3\n",
            "INFO:tensorflow:loss = 0.16847983, step = 2201 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.418\n",
            "INFO:tensorflow:loss = 0.10151926, step = 2301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.172\n",
            "INFO:tensorflow:loss = 0.08708249, step = 2401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.81\n",
            "INFO:tensorflow:loss = 0.02177193, step = 2501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1032.56\n",
            "INFO:tensorflow:loss = 0.061566632, step = 2601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.04\n",
            "INFO:tensorflow:loss = 0.6879441, step = 2701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.776\n",
            "INFO:tensorflow:loss = 0.040128045, step = 2801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.491\n",
            "INFO:tensorflow:loss = 0.09269664, step = 2901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.944\n",
            "INFO:tensorflow:loss = 0.17472509, step = 3001 (0.100 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3017 vs previous value: 3017. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 925.721\n",
            "INFO:tensorflow:loss = 0.04358639, step = 3101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.567\n",
            "INFO:tensorflow:loss = 0.036987025, step = 3201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.051\n",
            "INFO:tensorflow:loss = 0.20281334, step = 3301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.279\n",
            "INFO:tensorflow:loss = 0.024238028, step = 3401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.195\n",
            "INFO:tensorflow:loss = 0.017522244, step = 3501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 918\n",
            "INFO:tensorflow:loss = 0.01762914, step = 3601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.054\n",
            "INFO:tensorflow:loss = 0.0759746, step = 3701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.99\n",
            "INFO:tensorflow:loss = 0.027313706, step = 3801 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.929\n",
            "INFO:tensorflow:loss = 0.013714361, step = 3901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.805\n",
            "INFO:tensorflow:loss = 0.026104892, step = 4001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.344\n",
            "INFO:tensorflow:loss = 0.20500255, step = 4101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.683\n",
            "INFO:tensorflow:loss = 0.018361647, step = 4201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.189\n",
            "INFO:tensorflow:loss = 0.058891855, step = 4301 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.1\n",
            "INFO:tensorflow:loss = 0.027455512, step = 4401 (0.096 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4406 vs previous value: 4406. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 914.525\n",
            "INFO:tensorflow:loss = 0.93178856, step = 4501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.43\n",
            "INFO:tensorflow:loss = 0.017756192, step = 4601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.754\n",
            "INFO:tensorflow:loss = 0.014893862, step = 4701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.453\n",
            "INFO:tensorflow:loss = 0.021612242, step = 4801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.136\n",
            "INFO:tensorflow:loss = 0.043128666, step = 4901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1013.6\n",
            "INFO:tensorflow:loss = 0.4216265, step = 5001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.789\n",
            "INFO:tensorflow:loss = 0.02813597, step = 5101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.89\n",
            "INFO:tensorflow:loss = 0.020465333, step = 5201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.822\n",
            "INFO:tensorflow:loss = 0.031303283, step = 5301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 997.554\n",
            "INFO:tensorflow:loss = 0.035278138, step = 5401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 895.736\n",
            "INFO:tensorflow:loss = 0.039790362, step = 5501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.233\n",
            "INFO:tensorflow:loss = 0.081393376, step = 5601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.008\n",
            "INFO:tensorflow:loss = 0.030077552, step = 5701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.53\n",
            "INFO:tensorflow:loss = 0.023049334, step = 5801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.7\n",
            "INFO:tensorflow:loss = 0.11321649, step = 5901 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.165\n",
            "INFO:tensorflow:loss = 0.08385289, step = 6001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1013.61\n",
            "INFO:tensorflow:loss = 0.07113829, step = 6101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.393\n",
            "INFO:tensorflow:loss = 0.058963843, step = 6201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.75\n",
            "INFO:tensorflow:loss = 0.016578026, step = 6301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1025.57\n",
            "INFO:tensorflow:loss = 0.02017647, step = 6401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.725\n",
            "INFO:tensorflow:loss = 0.12256491, step = 6501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.11\n",
            "INFO:tensorflow:loss = 0.05624205, step = 6601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.383\n",
            "INFO:tensorflow:loss = 0.023000449, step = 6701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1021.84\n",
            "INFO:tensorflow:loss = 0.03969129, step = 6801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.649\n",
            "INFO:tensorflow:loss = 0.03997724, step = 6901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1037.1\n",
            "INFO:tensorflow:loss = 0.085032, step = 7001 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 922.642\n",
            "INFO:tensorflow:loss = 0.028574247, step = 7101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.451\n",
            "INFO:tensorflow:loss = 0.026306443, step = 7201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.016\n",
            "INFO:tensorflow:loss = 0.22864199, step = 7301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.08\n",
            "INFO:tensorflow:loss = 0.026908867, step = 7401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.999\n",
            "INFO:tensorflow:loss = 0.08185322, step = 7501 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1032.72\n",
            "INFO:tensorflow:loss = 0.038138516, step = 7601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.63\n",
            "INFO:tensorflow:loss = 0.031830005, step = 7701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.088\n",
            "INFO:tensorflow:loss = 0.019167729, step = 7801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.567\n",
            "INFO:tensorflow:loss = 0.021339396, step = 7901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.459\n",
            "INFO:tensorflow:loss = 0.09388441, step = 8001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.989\n",
            "INFO:tensorflow:loss = 0.016091365, step = 8101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.988\n",
            "INFO:tensorflow:loss = 0.019528214, step = 8201 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.339\n",
            "INFO:tensorflow:loss = 0.025139542, step = 8301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1028.2\n",
            "INFO:tensorflow:loss = 0.061138257, step = 8401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.516\n",
            "INFO:tensorflow:loss = 0.023499167, step = 8501 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1025.67\n",
            "INFO:tensorflow:loss = 0.032231793, step = 8601 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.85\n",
            "INFO:tensorflow:loss = 0.024664834, step = 8701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1046.5\n",
            "INFO:tensorflow:loss = 0.01704629, step = 8801 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.816\n",
            "INFO:tensorflow:loss = 0.13673401, step = 8901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.99\n",
            "INFO:tensorflow:loss = 0.039489094, step = 9001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1042.98\n",
            "INFO:tensorflow:loss = 0.042096257, step = 9101 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.085\n",
            "INFO:tensorflow:loss = 0.021728873, step = 9201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.62\n",
            "INFO:tensorflow:loss = 0.15288688, step = 9301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.435\n",
            "INFO:tensorflow:loss = 0.017871602, step = 9401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.77\n",
            "INFO:tensorflow:loss = 0.06680242, step = 9501 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.488\n",
            "INFO:tensorflow:loss = 0.38954172, step = 9601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.657\n",
            "INFO:tensorflow:loss = 0.015508648, step = 9701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.58\n",
            "INFO:tensorflow:loss = 0.7568923, step = 9801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.095\n",
            "INFO:tensorflow:loss = 0.048723906, step = 9901 (0.097 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_temp_min/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.02349579.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "LinearRegression has RMSE of 246.85797236897616\n",
            "Just using an average = 565.6027352653858, has RMSE of 133.15792625180381\n",
            "\n",
            "Sorry! On this run, your model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EshwsnjAYk7n"
      },
      "source": [
        "**1.1.1 Linear Regression Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In8EbhI1RYNY"
      },
      "source": [
        "Perform linear regression validation test using values from the original data set reserved for testing.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S646OaU0R8UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c08d48-72e5-40d8-e046-19f03ab82fe7"
      },
      "source": [
        "\n",
        "# Perform linear regression validation test using values from the original data set reserved for testing.                                                                                                 \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_temp_min', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "preds = estimator.predict(x=predictors_test.values)  # Use test data values \n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS  # Adjust for scale\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n--- Predicted number of collisions ---\\n\", pred)\n",
        "print(\"\\n-- ROW -- Number Collisions ----\\n\", df_test['NUM_COLLISIONS'].values)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff2041be240>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "--- Predicted number of collisions ---\n",
            " [801.1513  750.98083 747.4045  741.3095  868.7     856.78723 823.2898\n",
            " 823.6927  776.74615 718.61694 851.0951  780.22186 664.3665  810.0167\n",
            " 823.1636  774.02594 846.7127  839.5095  856.66125 795.6354  698.2416\n",
            " 829.1078  775.7891  742.11536 676.0528  780.9018  840.8948  798.5067\n",
            " 736.87683 855.1249  860.81696 822.1817  817.3457  713.479   778.8367\n",
            " 788.81024 838.6784  831.0217  715.51917 702.95123 715.2671  728.7164\n",
            " 676.48096 812.888   696.8563  779.1137  810.57086 842.8341  703.50543\n",
            " 682.32385]\n",
            "\n",
            "-- ROW -- Number Collisions ----\n",
            " [558 565 679 636 356 296 249 451 741 446 660 570 553 603 760 630 441 604\n",
            " 652 620 689 684 617 687 531 544 602 505 706 654 574 304 727 555 723 627\n",
            " 534 651 500 520 635 457 600 490 753 408 616 306 743 493]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGzbcuOCk1qz"
      },
      "source": [
        "Overall the linear regression model performed produced reasonable values at approximately the same accuracy as finding an average mean value, depending on how the data was shuffled.  The linear model appears to underestimate some of the outliers at maximum and minimum end of the range of values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNraI9oR-5i"
      },
      "source": [
        "# **1.2 Deep Neural Network Regressor**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajqj7Vmc3Qts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4637c2-3131-4f94-e09e-579b6fd35399"
      },
      "source": [
        "# Import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Required for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# Remove any previously saved training model training\n",
        "shutil.rmtree('/tmp/DNN_collision_regression_trained_model_temp_min', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_temp_min', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Print message to display start of training log\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model by passing predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE value to determine how well the model works using prediction and target values.\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nDNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store DNN regressoion value\n",
        "rmse_DNN = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate the mean of the Number of Collision Values.\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'])\n",
        "\n",
        "# Calculate RMSE using COLLISION Values and the mean of all target values to determine\n",
        "# if the DNN model is better than calculating the mean value.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Output success or failure message for this model\n",
        "if(rmse_DNN < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your DNN Regression model performs better than finding the average!'); # Success\n",
        "else: \n",
        "  print('\\nSorry! But on this run, your DNN Regression model performs worse than just finding the average!'); # Failure\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1a9a6a978>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_collision_regression_trained_model_temp_min/model.ckpt.\n",
            "INFO:tensorflow:loss = 14.677288, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 87 vs previous value: 87. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 505.553\n",
            "INFO:tensorflow:loss = 0.03583296, step = 101 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.603\n",
            "INFO:tensorflow:loss = 0.021911051, step = 201 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.843\n",
            "INFO:tensorflow:loss = 0.022354908, step = 301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.343\n",
            "INFO:tensorflow:loss = 0.01697667, step = 401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.7\n",
            "INFO:tensorflow:loss = 0.02167139, step = 501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.502\n",
            "INFO:tensorflow:loss = 0.026082143, step = 601 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.874\n",
            "INFO:tensorflow:loss = 0.019027118, step = 701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.521\n",
            "INFO:tensorflow:loss = 0.022149593, step = 801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.932\n",
            "INFO:tensorflow:loss = 0.022587543, step = 901 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.332\n",
            "INFO:tensorflow:loss = 0.019547412, step = 1001 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.753\n",
            "INFO:tensorflow:loss = 0.017117845, step = 1101 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.685\n",
            "INFO:tensorflow:loss = 0.028136885, step = 1201 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.89\n",
            "INFO:tensorflow:loss = 0.020708617, step = 1301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.799\n",
            "INFO:tensorflow:loss = 0.032679446, step = 1401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.266\n",
            "INFO:tensorflow:loss = 0.016049542, step = 1501 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.092\n",
            "INFO:tensorflow:loss = 0.035092443, step = 1601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.945\n",
            "INFO:tensorflow:loss = 0.020817442, step = 1701 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.66\n",
            "INFO:tensorflow:loss = 0.01750344, step = 1801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.128\n",
            "INFO:tensorflow:loss = 0.02254034, step = 1901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.449\n",
            "INFO:tensorflow:loss = 0.016640373, step = 2001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.809\n",
            "INFO:tensorflow:loss = 0.015065405, step = 2101 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.294\n",
            "INFO:tensorflow:loss = 0.023983747, step = 2201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.22\n",
            "INFO:tensorflow:loss = 0.019576177, step = 2301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.687\n",
            "INFO:tensorflow:loss = 0.023111029, step = 2401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.605\n",
            "INFO:tensorflow:loss = 0.028420415, step = 2501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.82\n",
            "INFO:tensorflow:loss = 0.021012112, step = 2601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.233\n",
            "INFO:tensorflow:loss = 0.018151186, step = 2701 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.65\n",
            "INFO:tensorflow:loss = 0.01606737, step = 2801 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.26\n",
            "INFO:tensorflow:loss = 0.020317934, step = 2901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.587\n",
            "INFO:tensorflow:loss = 0.017734041, step = 3001 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.231\n",
            "INFO:tensorflow:loss = 0.020177059, step = 3101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 709.312\n",
            "INFO:tensorflow:loss = 0.022926081, step = 3201 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.302\n",
            "INFO:tensorflow:loss = 0.018667858, step = 3301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.693\n",
            "INFO:tensorflow:loss = 0.017125461, step = 3401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.19\n",
            "INFO:tensorflow:loss = 0.013656577, step = 3501 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.184\n",
            "INFO:tensorflow:loss = 0.018013805, step = 3601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.714\n",
            "INFO:tensorflow:loss = 0.020468365, step = 3701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.684\n",
            "INFO:tensorflow:loss = 0.018224372, step = 3801 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.518\n",
            "INFO:tensorflow:loss = 0.01325102, step = 3901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.115\n",
            "INFO:tensorflow:loss = 0.0134221455, step = 4001 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.795\n",
            "INFO:tensorflow:loss = 0.016537555, step = 4101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.533\n",
            "INFO:tensorflow:loss = 0.024002448, step = 4201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.185\n",
            "INFO:tensorflow:loss = 0.014191059, step = 4301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.265\n",
            "INFO:tensorflow:loss = 0.017326124, step = 4401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.147\n",
            "INFO:tensorflow:loss = 0.019852858, step = 4501 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.073\n",
            "INFO:tensorflow:loss = 0.025897201, step = 4601 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.05\n",
            "INFO:tensorflow:loss = 0.014474565, step = 4701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.062\n",
            "INFO:tensorflow:loss = 0.023556322, step = 4801 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.994\n",
            "INFO:tensorflow:loss = 0.020888235, step = 4901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.321\n",
            "INFO:tensorflow:loss = 0.018472876, step = 5001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.996\n",
            "INFO:tensorflow:loss = 0.02048571, step = 5101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.972\n",
            "INFO:tensorflow:loss = 0.020095669, step = 5201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.829\n",
            "INFO:tensorflow:loss = 0.021479424, step = 5301 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.122\n",
            "INFO:tensorflow:loss = 0.015301722, step = 5401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.146\n",
            "INFO:tensorflow:loss = 0.014279706, step = 5501 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.677\n",
            "INFO:tensorflow:loss = 0.023178369, step = 5601 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.854\n",
            "INFO:tensorflow:loss = 0.024642957, step = 5701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.052\n",
            "INFO:tensorflow:loss = 0.018215578, step = 5801 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.765\n",
            "INFO:tensorflow:loss = 0.021788135, step = 5901 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.208\n",
            "INFO:tensorflow:loss = 0.020615028, step = 6001 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.582\n",
            "INFO:tensorflow:loss = 0.026191, step = 6101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.091\n",
            "INFO:tensorflow:loss = 0.01786052, step = 6201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.601\n",
            "INFO:tensorflow:loss = 0.016630609, step = 6301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.682\n",
            "INFO:tensorflow:loss = 0.016463818, step = 6401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.047\n",
            "INFO:tensorflow:loss = 0.014943441, step = 6501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.701\n",
            "INFO:tensorflow:loss = 0.014733475, step = 6601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.684\n",
            "INFO:tensorflow:loss = 0.016989373, step = 6701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.522\n",
            "INFO:tensorflow:loss = 0.016163563, step = 6801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.327\n",
            "INFO:tensorflow:loss = 0.0234467, step = 6901 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.629\n",
            "INFO:tensorflow:loss = 0.017757323, step = 7001 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.647\n",
            "INFO:tensorflow:loss = 0.016651385, step = 7101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.432\n",
            "INFO:tensorflow:loss = 0.01529817, step = 7201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.166\n",
            "INFO:tensorflow:loss = 0.018862048, step = 7301 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.643\n",
            "INFO:tensorflow:loss = 0.022467127, step = 7401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.915\n",
            "INFO:tensorflow:loss = 0.020956203, step = 7501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.067\n",
            "INFO:tensorflow:loss = 0.016154446, step = 7601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.725\n",
            "INFO:tensorflow:loss = 0.019670658, step = 7701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.637\n",
            "INFO:tensorflow:loss = 0.015649814, step = 7801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.371\n",
            "INFO:tensorflow:loss = 0.021295257, step = 7901 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.573\n",
            "INFO:tensorflow:loss = 0.017714426, step = 8001 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.521\n",
            "INFO:tensorflow:loss = 0.016559321, step = 8101 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.626\n",
            "INFO:tensorflow:loss = 0.015392422, step = 8201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.744\n",
            "INFO:tensorflow:loss = 0.016784051, step = 8301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.087\n",
            "INFO:tensorflow:loss = 0.016444454, step = 8401 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.146\n",
            "INFO:tensorflow:loss = 0.014772835, step = 8501 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.958\n",
            "INFO:tensorflow:loss = 0.024178527, step = 8601 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.915\n",
            "INFO:tensorflow:loss = 0.017303474, step = 8701 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.49\n",
            "INFO:tensorflow:loss = 0.017018104, step = 8801 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.367\n",
            "INFO:tensorflow:loss = 0.022387743, step = 8901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.655\n",
            "INFO:tensorflow:loss = 0.01999994, step = 9001 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.588\n",
            "INFO:tensorflow:loss = 0.01803756, step = 9101 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.961\n",
            "INFO:tensorflow:loss = 0.017544322, step = 9201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.979\n",
            "INFO:tensorflow:loss = 0.01544348, step = 9301 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.778\n",
            "INFO:tensorflow:loss = 0.019367542, step = 9401 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.277\n",
            "INFO:tensorflow:loss = 0.015417422, step = 9501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.2\n",
            "INFO:tensorflow:loss = 0.017808484, step = 9601 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.585\n",
            "INFO:tensorflow:loss = 0.016784362, step = 9701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.909\n",
            "INFO:tensorflow:loss = 0.019983394, step = 9801 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 709.781\n",
            "INFO:tensorflow:loss = 0.014074997, step = 9901 (0.142 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_collision_regression_trained_model_temp_min/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.015141496.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "DNNRegression has RMSE of 133.13446628941077\n",
            "Just using average = 565.6027352653858 has RMSE of 133.15792625180381\n",
            "\n",
            "Great! Your DNN Regression model performs better than finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV7aUldnTHG7"
      },
      "source": [
        "**1.2.1 Deep Neural Network Validation Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwmIaI6_5FYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5ce160-adcb-4b47-8f20-73472fb3a002"
      },
      "source": [
        "# Perform validation assessment of DNN model using test values reserved from original dataset\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_temp_min', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "# Use test values reserved from original data set\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n====Target Collision Values====\", targets_test.values)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff2046cdef0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [574.33734 573.71643 571.78174 570.7368  578.92194 578.9247  576.27094\n",
            " 575.61365 572.66724 570.61053 578.26874 573.68506 566.02313 574.6968\n",
            " 581.85846 576.0679  577.6455  577.2857  579.2204  579.18146 568.151\n",
            " 576.6309  573.3247  573.9217  566.48096 573.0159  577.2854  574.04224\n",
            " 570.73785 578.925   579.2195  576.6326  579.8988  571.7167  573.6854\n",
            " 574.04456 577.2859  577.5262  569.42847 569.9009  574.19476 574.78577\n",
            " 566.77606 575.97754 568.1653  573.6853  574.69666 577.2849  568.1498\n",
            " 571.73096]\n",
            "\n",
            "====Target Collision Values==== [558 565 679 636 356 296 249 451 741 446 660 570 553 603 760 630 441 604\n",
            " 652 620 689 684 617 687 531 544 602 505 706 654 574 304 727 555 723 627\n",
            " 534 651 500 520 635 457 600 490 753 408 616 306 743 493]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtuWGFuoQOEo"
      },
      "source": [
        "From the results of the DNN validation test, for most runs, it was seen that many of the predicted values are an approximation to the target values, although many of the very large and small target values were under-estimated by the DNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZdUMVjbOv-r"
      },
      "source": [
        "# **1.3 Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2k8kPfuO0RP"
      },
      "source": [
        "From the results of the linear and DNN models, we can see that the linear model performed worse than just finding the average number of collisions using a mean value on about half the runs, but the DNN model performed better than finding the average on the majority of occasions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUkcLhjqUHsX"
      },
      "source": [
        "#**2. Day, Month and Minimum Temperature**\r\n",
        "\r\n",
        "I will now investigate if adding day and month data to weather and temperature  factors, changes the performance of the models.  I will also use a different dataset with enhanced cleansing and normalisation of weather data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlZPMaUUHsg"
      },
      "source": [
        "# Import pandas to allow creation of data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Create data frame from github csv file\n",
        "source_dataframe = pd.read_csv('https://raw.githubusercontent.com/15014370uhi/15014370_DataAnalytics/master/bq-cleansed_weather_reduced_assignment_1.csv', index_col=0,);"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnZPVK5sUHsh",
        "outputId": "488d19fc-f60a-4d11-dbf3-eb6a6512d1f0"
      },
      "source": [
        "# Check that correct data is present\n",
        "print(source_dataframe) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  da  day  temp  dewp  ...  mxpsd   max   min  prcp  NUM_COLLISIONS\n",
            "year                           ...                                         \n",
            "2012   7   1    7  83.6  63.0  ...    9.9  93.0  66.0  0.00             538\n",
            "2012   7   2    1  80.3  54.1  ...   15.0  88.0  66.9  0.00             564\n",
            "2012   7   3    2  79.8  56.7  ...   12.0  88.0  63.0  0.00             664\n",
            "2012   7   4    3  81.8  65.6  ...   11.1  91.0  68.0  0.06             432\n",
            "2012   7   6    5  81.9  62.3  ...    9.9  91.0  66.9  0.00             638\n",
            "...   ..  ..  ...   ...   ...  ...    ...   ...   ...   ...             ...\n",
            "2020  12   1    2  58.1  54.3  ...   34.0  63.0  45.0  0.88             253\n",
            "2020  12   2    3  47.5  35.9  ...   22.9  63.0  42.1  0.59             204\n",
            "2020  12   3    4  45.1  32.4  ...   18.1  52.0  36.0  0.02             218\n",
            "2020  12   4    5  53.6  43.8  ...   18.1  59.0  36.0  0.00             319\n",
            "2020  12   5    6  51.9  48.9  ...   32.1  59.0  39.9  0.32             222\n",
            "\n",
            "[3054 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbH6o9abUHsh",
        "outputId": "da597af4-b2f0-4e05-c221-b3028d6cb476"
      },
      "source": [
        "# Find the total length of data rows\r\n",
        "totalNumberOfRows = len(source_dataframe);\r\n",
        "print(totalNumberOfRows);"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKtv2g5BUHsh"
      },
      "source": [
        "# Import numpty to improve speed of math calculations\n",
        "import numpy as np"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKw9xYavUHsi"
      },
      "source": [
        "# Shuffle all source data\r\n",
        "source_dataframe = source_dataframe.iloc[np.random.permutation(len(source_dataframe))]; "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKxqYTFpUHsi"
      },
      "source": [
        "# Number of rows to reserve for testing\r\n",
        "number_of_test_rows = 50"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrgFqfUjUHsi"
      },
      "source": [
        "# Store training data as (all rows - number_of_test_rows) of source data\n",
        "df_train = source_dataframe[:-number_of_test_rows];\n",
        "\n",
        "# Shuffle training data a second time\n",
        "df_train = df_train.iloc[np.random.permutation(len(df_train))]; \n",
        "\n",
        "# Store validation test data as last number_of_test_rows of rows of source data\n",
        "df_test = source_dataframe[-number_of_test_rows:];\n",
        "\n",
        "# Shuffle test data a second time\n",
        "df_test = df_test.iloc[np.random.permutation(len(df_test))];\n",
        "\n",
        "# Store only relevant columns of data for this model\n",
        "df_train = df_train.iloc[:, [2,3,10,12]]; \n",
        "df_test = df_test.iloc[:, [2,3,10,12]];\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS8XHUdAUHsi",
        "outputId": "af082fe3-55fd-487a-9139-2e6d45eae868"
      },
      "source": [
        "# Confirm training data is stored \r\n",
        "print(df_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      day  temp   min  NUM_COLLISIONS\n",
            "year                                 \n",
            "2018    5  38.0  27.0             705\n",
            "2014    1  44.6  37.0             625\n",
            "2013    3  55.3  44.1             539\n",
            "2014    4  52.0  46.0             596\n",
            "2016    2  73.8  66.9             699\n",
            "...   ...   ...   ...             ...\n",
            "2015    2  65.5  59.0             703\n",
            "2013    6  66.2  55.9             527\n",
            "2013    4  42.8  30.0             620\n",
            "2020    4  44.6  39.0             581\n",
            "2019    6  67.1  55.9             602\n",
            "\n",
            "[3004 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neMwzWlTUHsj",
        "outputId": "d67583d9-fc0c-462d-9089-b50d6ddc3db0"
      },
      "source": [
        "# Confirm test data rows are stored\r\n",
        "print(df_test);"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      day  temp   min  NUM_COLLISIONS\n",
            "year                                 \n",
            "2020    4  60.7  51.8             322\n",
            "2016    7  51.3  37.9             518\n",
            "2014    1  50.9  39.0             451\n",
            "2019    5  73.7  69.1             645\n",
            "2015    1  67.6  63.0             579\n",
            "2016    3  45.7  37.0             653\n",
            "2012    1  65.3  61.0             607\n",
            "2019    3  35.6  28.0             264\n",
            "2015    5  67.0  61.0             451\n",
            "2013    6  69.3  66.0             492\n",
            "2019    3  43.7  39.9             613\n",
            "2013    7  35.7  23.0             393\n",
            "2013    6  24.4  21.9             558\n",
            "2016    7  67.5  64.4             529\n",
            "2019    7  38.4  30.9             384\n",
            "2014    3  67.5  53.1             538\n",
            "2015    4  59.7  57.0             683\n",
            "2020    4  40.6  30.9             455\n",
            "2017    3  62.6  60.1             744\n",
            "2019    3  62.3  57.9             591\n",
            "2016    4  73.6  66.9             672\n",
            "2017    5  13.7   6.1             598\n",
            "2017    3  29.8  25.0             650\n",
            "2017    3  53.9  50.0             641\n",
            "2019    2  48.8  44.1             592\n",
            "2014    2  22.2  17.1             504\n",
            "2015    7  41.6  34.0             422\n",
            "2019    6  23.5  10.9             577\n",
            "2019    6  39.3  32.0             530\n",
            "2019    7  26.0  18.0             374\n",
            "2015    3  73.9  69.1             594\n",
            "2015    3  65.2  57.9             667\n",
            "2019    6  51.9  42.1             557\n",
            "2016    3  45.0  41.0             510\n",
            "2012    6  43.6  39.0             542\n",
            "2013    4  69.8  68.0             438\n",
            "2016    7  57.6  48.0             572\n",
            "2013    7  64.0  50.0             459\n",
            "2014    6  59.4  57.0             531\n",
            "2015    6  21.9   3.9             517\n",
            "2015    7  57.0  52.0             312\n",
            "2017    1  51.1  48.0             729\n",
            "2014    3  69.2  60.1             591\n",
            "2020    7  51.3  46.9             166\n",
            "2019    7  43.2  28.0             411\n",
            "2019    7  56.9  52.0             515\n",
            "2015    4  32.7  24.1             830\n",
            "2019    6  35.3  32.0             502\n",
            "2020    4  63.5  57.0             309\n",
            "2016    6  62.6  53.1             700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXAhCxZkUHsj"
      },
      "source": [
        "# Select Predictor columns for training and testing data to be used to predict the outcome\n",
        "\n",
        "predictors_train = df_train.iloc[:, [0,1,2]];\n",
        "predictors_test = df_test.iloc[:,  [0,1,2]];"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4_YqNxdUHsj",
        "outputId": "35c94d5c-0854-40c3-eabd-c96437cd7c16"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      day  temp   min\n",
            "year                 \n",
            "2018    5  38.0  27.0\n",
            "2014    1  44.6  37.0\n",
            "2013    3  55.3  44.1\n",
            "2014    4  52.0  46.0\n",
            "2016    2  73.8  66.9\n",
            "...   ...   ...   ...\n",
            "2015    2  65.5  59.0\n",
            "2013    6  66.2  55.9\n",
            "2013    4  42.8  30.0\n",
            "2020    4  44.6  39.0\n",
            "2019    6  67.1  55.9\n",
            "\n",
            "[3004 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blvj5WAvUHsj",
        "outputId": "3088d76e-d56b-4a0e-de9f-37b2ec92a379"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_test);"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      day  temp   min\n",
            "year                 \n",
            "2020    4  60.7  51.8\n",
            "2016    7  51.3  37.9\n",
            "2014    1  50.9  39.0\n",
            "2019    5  73.7  69.1\n",
            "2015    1  67.6  63.0\n",
            "2016    3  45.7  37.0\n",
            "2012    1  65.3  61.0\n",
            "2019    3  35.6  28.0\n",
            "2015    5  67.0  61.0\n",
            "2013    6  69.3  66.0\n",
            "2019    3  43.7  39.9\n",
            "2013    7  35.7  23.0\n",
            "2013    6  24.4  21.9\n",
            "2016    7  67.5  64.4\n",
            "2019    7  38.4  30.9\n",
            "2014    3  67.5  53.1\n",
            "2015    4  59.7  57.0\n",
            "2020    4  40.6  30.9\n",
            "2017    3  62.6  60.1\n",
            "2019    3  62.3  57.9\n",
            "2016    4  73.6  66.9\n",
            "2017    5  13.7   6.1\n",
            "2017    3  29.8  25.0\n",
            "2017    3  53.9  50.0\n",
            "2019    2  48.8  44.1\n",
            "2014    2  22.2  17.1\n",
            "2015    7  41.6  34.0\n",
            "2019    6  23.5  10.9\n",
            "2019    6  39.3  32.0\n",
            "2019    7  26.0  18.0\n",
            "2015    3  73.9  69.1\n",
            "2015    3  65.2  57.9\n",
            "2019    6  51.9  42.1\n",
            "2016    3  45.0  41.0\n",
            "2012    6  43.6  39.0\n",
            "2013    4  69.8  68.0\n",
            "2016    7  57.6  48.0\n",
            "2013    7  64.0  50.0\n",
            "2014    6  59.4  57.0\n",
            "2015    6  21.9   3.9\n",
            "2015    7  57.0  52.0\n",
            "2017    1  51.1  48.0\n",
            "2014    3  69.2  60.1\n",
            "2020    7  51.3  46.9\n",
            "2019    7  43.2  28.0\n",
            "2019    7  56.9  52.0\n",
            "2015    4  32.7  24.1\n",
            "2019    6  35.3  32.0\n",
            "2020    4  63.5  57.0\n",
            "2016    6  62.6  53.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FtFR5HgUHsj"
      },
      "source": [
        "# Select target columns\n",
        "targets_train = df_train.iloc[:,3];\n",
        "\n",
        "# Select target columns\n",
        "targets_test = df_test.iloc[:,3];"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnCmw7g9UHsj",
        "outputId": "2e9ea1f8-943b-4bb2-ed9d-0bf6aa79973b"
      },
      "source": [
        "print(targets_train);"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2018    705\n",
            "2014    625\n",
            "2013    539\n",
            "2014    596\n",
            "2016    699\n",
            "       ... \n",
            "2015    703\n",
            "2013    527\n",
            "2013    620\n",
            "2020    581\n",
            "2019    602\n",
            "Name: NUM_COLLISIONS, Length: 3004, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx-oRyRsUHsk",
        "outputId": "21c1980c-2e1d-42db-fa8a-6718fbe0adf7"
      },
      "source": [
        "print(targets_test);"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2020    322\n",
            "2016    518\n",
            "2014    451\n",
            "2019    645\n",
            "2015    579\n",
            "2016    653\n",
            "2012    607\n",
            "2019    264\n",
            "2015    451\n",
            "2013    492\n",
            "2019    613\n",
            "2013    393\n",
            "2013    558\n",
            "2016    529\n",
            "2019    384\n",
            "2014    538\n",
            "2015    683\n",
            "2020    455\n",
            "2017    744\n",
            "2019    591\n",
            "2016    672\n",
            "2017    598\n",
            "2017    650\n",
            "2017    641\n",
            "2019    592\n",
            "2014    504\n",
            "2015    422\n",
            "2019    577\n",
            "2019    530\n",
            "2019    374\n",
            "2015    594\n",
            "2015    667\n",
            "2019    557\n",
            "2016    510\n",
            "2012    542\n",
            "2013    438\n",
            "2016    572\n",
            "2013    459\n",
            "2014    531\n",
            "2015    517\n",
            "2015    312\n",
            "2017    729\n",
            "2014    591\n",
            "2020    166\n",
            "2019    411\n",
            "2019    515\n",
            "2015    830\n",
            "2019    502\n",
            "2020    309\n",
            "2016    700\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbZz7fW3UHsk"
      },
      "source": [
        "# Set scale value\n",
        "SCALE_NUM_COLLISIONS = 1000.0;"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSQ7mXCEUHsl"
      },
      "source": [
        "# Get size of training set \n",
        "trainsize = int(len(df_train['NUM_COLLISIONS']));\n",
        "\n",
        "# Get size of test set \n",
        "testsize = int(len(df_test['NUM_COLLISIONS']));"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHfgMZxHUHsl",
        "outputId": "1599d114-7621-4cdd-fe8a-d2e735e41cdc"
      },
      "source": [
        "print(trainsize);"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOOGLFRUUHsl",
        "outputId": "8cdca223-7e66-4638-ad56-101500f583ec"
      },
      "source": [
        "print(testsize);"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa-b5p-EUHsl"
      },
      "source": [
        "\r\n",
        "# Define the number of predictor column input values\r\n",
        "nppredictors = len(predictors_train.columns);\r\n",
        "\r\n",
        "# Define the number of target column output values\r\n",
        "noutputs = 1;\r\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9T5-UOTUHsl",
        "outputId": "ea7aa2b9-bfd4-4605-bab4-a5aaf23d6f83"
      },
      "source": [
        "print(nppredictors)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d0yK_UPUHsl"
      },
      "source": [
        "# **2.1 Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPECpSBHUHsl",
        "outputId": "c0833a99-5da6-45a0-ecb0-0e70a5872cd3"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_mo_day_temp_min', ignore_errors=True)\n",
        "   \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_mo_day_temp_min', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Prints log to show start of training model\n",
        "print(\"starting to train...\\n\");\n",
        "\n",
        "# Train the model using predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Check predictions based on predictor values\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply Scale value to outputs\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE using predictions and targets\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nLinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store linear regressor value\n",
        "rmse_LR = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate mean value of Number of Collisions\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Number of Collision Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2));\n",
        "print('Just using an average = {0}, has RMSE of {1}'.format(avg, rmse)); \n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "if(rmse_LR < rmse_avg): # If DNN rmse is lower than average rmse\n",
        "  print('\\nGreat! Your Linear Regression model performs better than finding average!');\n",
        "else: \n",
        "  print('\\nSorry! On this run, your model performs worse than just finding the average!');\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1afb89f60>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_mo_day_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "starting to train...\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_mo_day_temp_min/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.34138602, step = 1\n",
            "INFO:tensorflow:global_step/sec: 829.388\n",
            "INFO:tensorflow:loss = 0.02442741, step = 101 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.222\n",
            "INFO:tensorflow:loss = 0.019626945, step = 201 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 997.627\n",
            "INFO:tensorflow:loss = 0.02156731, step = 301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.485\n",
            "INFO:tensorflow:loss = 0.021848531, step = 401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.337\n",
            "INFO:tensorflow:loss = 0.018115003, step = 501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1038.08\n",
            "INFO:tensorflow:loss = 0.018682657, step = 601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.588\n",
            "INFO:tensorflow:loss = 0.017107662, step = 701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.28\n",
            "INFO:tensorflow:loss = 0.026286252, step = 801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.747\n",
            "INFO:tensorflow:loss = 0.029570797, step = 901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.624\n",
            "INFO:tensorflow:loss = 0.015335735, step = 1001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.557\n",
            "INFO:tensorflow:loss = 0.02482181, step = 1101 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.964\n",
            "INFO:tensorflow:loss = 0.016224423, step = 1201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 895.497\n",
            "INFO:tensorflow:loss = 0.018806824, step = 1301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.951\n",
            "INFO:tensorflow:loss = 0.031382438, step = 1401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.767\n",
            "INFO:tensorflow:loss = 0.05862802, step = 1501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.07\n",
            "INFO:tensorflow:loss = 0.02841432, step = 1601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.155\n",
            "INFO:tensorflow:loss = 0.023833962, step = 1701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1026.3\n",
            "INFO:tensorflow:loss = 0.024048708, step = 1801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.643\n",
            "INFO:tensorflow:loss = 0.084131196, step = 1901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.69\n",
            "INFO:tensorflow:loss = 0.09323138, step = 2001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.808\n",
            "INFO:tensorflow:loss = 0.021229025, step = 2101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.699\n",
            "INFO:tensorflow:loss = 0.12550779, step = 2201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.56\n",
            "INFO:tensorflow:loss = 0.048180863, step = 2301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.927\n",
            "INFO:tensorflow:loss = 0.12621447, step = 2401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.08\n",
            "INFO:tensorflow:loss = 0.052772485, step = 2501 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.671\n",
            "INFO:tensorflow:loss = 0.020476542, step = 2601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1043.14\n",
            "INFO:tensorflow:loss = 0.033864774, step = 2701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.965\n",
            "INFO:tensorflow:loss = 0.02089433, step = 2801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.932\n",
            "INFO:tensorflow:loss = 0.06257614, step = 2901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.869\n",
            "INFO:tensorflow:loss = 0.01613583, step = 3001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.122\n",
            "INFO:tensorflow:loss = 0.07042929, step = 3101 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.872\n",
            "INFO:tensorflow:loss = 0.20106928, step = 3201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.578\n",
            "INFO:tensorflow:loss = 0.02760679, step = 3301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.241\n",
            "INFO:tensorflow:loss = 0.033831216, step = 3401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.885\n",
            "INFO:tensorflow:loss = 0.018023124, step = 3501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.39\n",
            "INFO:tensorflow:loss = 0.047518503, step = 3601 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.277\n",
            "INFO:tensorflow:loss = 0.04049049, step = 3701 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.667\n",
            "INFO:tensorflow:loss = 0.06903366, step = 3801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.937\n",
            "INFO:tensorflow:loss = 0.09133458, step = 3901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.46\n",
            "INFO:tensorflow:loss = 0.018804658, step = 4001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 875.153\n",
            "INFO:tensorflow:loss = 0.017879765, step = 4101 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.094\n",
            "INFO:tensorflow:loss = 0.01790822, step = 4201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.583\n",
            "INFO:tensorflow:loss = 0.029519508, step = 4301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.383\n",
            "INFO:tensorflow:loss = 0.019313624, step = 4401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.274\n",
            "INFO:tensorflow:loss = 0.23346847, step = 4501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.95\n",
            "INFO:tensorflow:loss = 0.044171892, step = 4601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.791\n",
            "INFO:tensorflow:loss = 0.030475989, step = 4701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.23\n",
            "INFO:tensorflow:loss = 0.07043252, step = 4801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.199\n",
            "INFO:tensorflow:loss = 0.27190542, step = 4901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.421\n",
            "INFO:tensorflow:loss = 0.045344256, step = 5001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.506\n",
            "INFO:tensorflow:loss = 0.11471215, step = 5101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.916\n",
            "INFO:tensorflow:loss = 0.031366948, step = 5201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.486\n",
            "INFO:tensorflow:loss = 0.07512423, step = 5301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.88\n",
            "INFO:tensorflow:loss = 0.047893263, step = 5401 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.189\n",
            "INFO:tensorflow:loss = 0.022001315, step = 5501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.129\n",
            "INFO:tensorflow:loss = 0.020534009, step = 5601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.272\n",
            "INFO:tensorflow:loss = 0.17612055, step = 5701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1028.46\n",
            "INFO:tensorflow:loss = 0.0163313, step = 5801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.025\n",
            "INFO:tensorflow:loss = 0.055286713, step = 5901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.02\n",
            "INFO:tensorflow:loss = 0.09663929, step = 6001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.507\n",
            "INFO:tensorflow:loss = 0.21782377, step = 6101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.319\n",
            "INFO:tensorflow:loss = 0.06093522, step = 6201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.202\n",
            "INFO:tensorflow:loss = 0.30674264, step = 6301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.847\n",
            "INFO:tensorflow:loss = 0.16460338, step = 6401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.802\n",
            "INFO:tensorflow:loss = 0.050784662, step = 6501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007.28\n",
            "INFO:tensorflow:loss = 0.021537816, step = 6601 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.813\n",
            "INFO:tensorflow:loss = 0.06701096, step = 6701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1037.87\n",
            "INFO:tensorflow:loss = 0.40145382, step = 6801 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.758\n",
            "INFO:tensorflow:loss = 0.018060751, step = 6901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.092\n",
            "INFO:tensorflow:loss = 0.08130424, step = 7001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.78\n",
            "INFO:tensorflow:loss = 0.029156156, step = 7101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.776\n",
            "INFO:tensorflow:loss = 0.12790737, step = 7201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1046.84\n",
            "INFO:tensorflow:loss = 0.19343594, step = 7301 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.625\n",
            "INFO:tensorflow:loss = 0.02029845, step = 7401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.87\n",
            "INFO:tensorflow:loss = 0.023590282, step = 7501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.971\n",
            "INFO:tensorflow:loss = 0.018069096, step = 7601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1042.56\n",
            "INFO:tensorflow:loss = 0.019932806, step = 7701 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.184\n",
            "INFO:tensorflow:loss = 0.018753247, step = 7801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.35\n",
            "INFO:tensorflow:loss = 0.6950569, step = 7901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.385\n",
            "INFO:tensorflow:loss = 0.3146804, step = 8001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.77\n",
            "INFO:tensorflow:loss = 0.025448374, step = 8101 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.624\n",
            "INFO:tensorflow:loss = 0.018526161, step = 8201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.306\n",
            "INFO:tensorflow:loss = 0.032226257, step = 8301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.711\n",
            "INFO:tensorflow:loss = 0.024141986, step = 8401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.62\n",
            "INFO:tensorflow:loss = 0.02812568, step = 8501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.598\n",
            "INFO:tensorflow:loss = 0.023728952, step = 8601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1052.27\n",
            "INFO:tensorflow:loss = 0.060691603, step = 8701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.97\n",
            "INFO:tensorflow:loss = 0.034245458, step = 8801 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1012.2\n",
            "INFO:tensorflow:loss = 0.021199178, step = 8901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.525\n",
            "INFO:tensorflow:loss = 0.28146863, step = 9001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.925\n",
            "INFO:tensorflow:loss = 0.11286546, step = 9101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.515\n",
            "INFO:tensorflow:loss = 0.24828553, step = 9201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.705\n",
            "INFO:tensorflow:loss = 0.01869357, step = 9301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1019.06\n",
            "INFO:tensorflow:loss = 0.02335484, step = 9401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.494\n",
            "INFO:tensorflow:loss = 0.019688208, step = 9501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.621\n",
            "INFO:tensorflow:loss = 0.024215799, step = 9601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1016.04\n",
            "INFO:tensorflow:loss = 0.034308754, step = 9701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.408\n",
            "INFO:tensorflow:loss = 0.028211966, step = 9801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1016.3\n",
            "INFO:tensorflow:loss = 0.022729129, step = 9901 (0.098 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_mo_day_temp_min/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.01513583.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_mo_day_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "LinearRegression has RMSE of 149.72118837467804\n",
            "Just using an average = 564.9756990679094, has RMSE of 135.34001077774784\n",
            "\n",
            "Sorry! On this run, your model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNfGqQEpUHsm"
      },
      "source": [
        "**2.1.1 Linear Regression Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFnyCkTyUHsm"
      },
      "source": [
        "Perform linear regression validation test using values from the original data set reserved for testing.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVCW0UWKUHsm",
        "outputId": "bb1ce1a7-09d6-42e3-8b5c-02b75975ec26"
      },
      "source": [
        "\n",
        "# Perform linear regression validation test using values from the original data set reserved for testing.                                                                                                 \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_mo_day_temp_min', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "preds = estimator.predict(x=predictors_test.values)  # Use test data values \n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS  # Adjust for scale\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1afcd9cc0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_mo_day_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_mo_day_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [647.6338  598.0896  658.0376  663.84985 692.32587 629.0023  688.0143\n",
            " 610.0003  650.57446 645.7896  626.71277 568.42566 560.02856 632.36395\n",
            " 575.2341  668.97003 647.6689  608.87744 663.3276  662.1551  673.0379\n",
            " 547.9668  599.77057 646.22095 646.23975 595.1576  581.3327  555.1265\n",
            " 587.06146 551.3227  684.2508  666.798   610.4121  629.14014 596.1483\n",
            " 667.3002  611.3539  622.22955 627.10785 550.3625  611.6518  661.18964\n",
            " 673.8943  600.9214  582.0065  611.4917  594.0899  580.6574  653.75275\n",
            " 631.00397]\n",
            "\n",
            "==== Target Collision Values ==== [322 518 451 645 579 653 607 264 451 492 613 393 558 529 384 538 683 455\n",
            " 744 591 672 598 650 641 592 504 422 577 530 374 594 667 557 510 542 438\n",
            " 572 459 531 517 312 729 591 166 411 515 830 502 309 700]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFV8IrkrUHsn"
      },
      "source": [
        "# **2.2 Deep Neural Network Regressor**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAVHPHUVUHsn",
        "outputId": "631b87fc-2f74-452d-cf3c-44bd2be45824"
      },
      "source": [
        "# Import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Required for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# Remove any previously saved training model training\n",
        "shutil.rmtree('/tmp/DNN_collision_regression_trained_model_mo_day_temp_min', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_mo_day_temp_min', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Print message to display start of training log\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model by passing predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE value to determine how well the model works using prediction and target values.\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nDNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store DNN regressoion value\n",
        "rmse_DNN = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate the mean of the Number of Collision Values.\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'])\n",
        "\n",
        "# Calculate RMSE using COLLISION Values and the mean of all target values to determine\n",
        "# if the DNN model is better than calculating the mean value.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Output success or failure message for this model\n",
        "if(rmse_DNN < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your DNN Regression model performs better than finding the average!'); # Success\n",
        "else: \n",
        "  print('\\nSorry! But on this run, your DNN Regression model performs worse than just finding the average!'); # Failure\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1afa9a278>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_mo_day_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_collision_regression_trained_model_mo_day_temp_min/model.ckpt.\n",
            "INFO:tensorflow:loss = 6.5330257, step = 1\n",
            "INFO:tensorflow:global_step/sec: 509.928\n",
            "INFO:tensorflow:loss = 0.028435234, step = 101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.312\n",
            "INFO:tensorflow:loss = 0.021278668, step = 201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.328\n",
            "INFO:tensorflow:loss = 0.022651793, step = 301 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.902\n",
            "INFO:tensorflow:loss = 0.017835952, step = 401 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.344\n",
            "INFO:tensorflow:loss = 0.018057859, step = 501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.034\n",
            "INFO:tensorflow:loss = 0.018665658, step = 601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.361\n",
            "INFO:tensorflow:loss = 0.017591538, step = 701 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.626\n",
            "INFO:tensorflow:loss = 0.02168365, step = 801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.428\n",
            "INFO:tensorflow:loss = 0.017365031, step = 901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.893\n",
            "INFO:tensorflow:loss = 0.013970364, step = 1001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.059\n",
            "INFO:tensorflow:loss = 0.020121608, step = 1101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.415\n",
            "INFO:tensorflow:loss = 0.021384854, step = 1201 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.898\n",
            "INFO:tensorflow:loss = 0.017034378, step = 1301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.233\n",
            "INFO:tensorflow:loss = 0.022118619, step = 1401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.789\n",
            "INFO:tensorflow:loss = 0.017238118, step = 1501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.463\n",
            "INFO:tensorflow:loss = 0.018778995, step = 1601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.229\n",
            "INFO:tensorflow:loss = 0.02145525, step = 1701 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.82\n",
            "INFO:tensorflow:loss = 0.02182759, step = 1801 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.206\n",
            "INFO:tensorflow:loss = 0.015777132, step = 1901 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.805\n",
            "INFO:tensorflow:loss = 0.020491984, step = 2001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.691\n",
            "INFO:tensorflow:loss = 0.014449913, step = 2101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.177\n",
            "INFO:tensorflow:loss = 0.01380429, step = 2201 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.151\n",
            "INFO:tensorflow:loss = 0.015720911, step = 2301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.505\n",
            "INFO:tensorflow:loss = 0.023765657, step = 2401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.469\n",
            "INFO:tensorflow:loss = 0.013889722, step = 2501 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.246\n",
            "INFO:tensorflow:loss = 0.016737469, step = 2601 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.68\n",
            "INFO:tensorflow:loss = 0.016224027, step = 2701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.161\n",
            "INFO:tensorflow:loss = 0.020084225, step = 2801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.33\n",
            "INFO:tensorflow:loss = 0.018450435, step = 2901 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.614\n",
            "INFO:tensorflow:loss = 0.016019471, step = 3001 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.177\n",
            "INFO:tensorflow:loss = 0.018132925, step = 3101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.354\n",
            "INFO:tensorflow:loss = 0.02537033, step = 3201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.256\n",
            "INFO:tensorflow:loss = 0.016695037, step = 3301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.495\n",
            "INFO:tensorflow:loss = 0.022336682, step = 3401 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.22\n",
            "INFO:tensorflow:loss = 0.018901393, step = 3501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.872\n",
            "INFO:tensorflow:loss = 0.016272578, step = 3601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.974\n",
            "INFO:tensorflow:loss = 0.018105038, step = 3701 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.366\n",
            "INFO:tensorflow:loss = 0.019651271, step = 3801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.828\n",
            "INFO:tensorflow:loss = 0.016402438, step = 3901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.836\n",
            "INFO:tensorflow:loss = 0.015993932, step = 4001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.476\n",
            "INFO:tensorflow:loss = 0.017117813, step = 4101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.72\n",
            "INFO:tensorflow:loss = 0.017814118, step = 4201 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.78\n",
            "INFO:tensorflow:loss = 0.01574588, step = 4301 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.717\n",
            "INFO:tensorflow:loss = 0.017963363, step = 4401 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.725\n",
            "INFO:tensorflow:loss = 0.015542956, step = 4501 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.144\n",
            "INFO:tensorflow:loss = 0.023240611, step = 4601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.538\n",
            "INFO:tensorflow:loss = 0.016938267, step = 4701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.219\n",
            "INFO:tensorflow:loss = 0.013182647, step = 4801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.424\n",
            "INFO:tensorflow:loss = 0.0170922, step = 4901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.331\n",
            "INFO:tensorflow:loss = 0.01816272, step = 5001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.158\n",
            "INFO:tensorflow:loss = 0.02084939, step = 5101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.134\n",
            "INFO:tensorflow:loss = 0.011955303, step = 5201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.074\n",
            "INFO:tensorflow:loss = 0.013990944, step = 5301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.211\n",
            "INFO:tensorflow:loss = 0.012166336, step = 5401 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.972\n",
            "INFO:tensorflow:loss = 0.017763361, step = 5501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.524\n",
            "INFO:tensorflow:loss = 0.015156661, step = 5601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.739\n",
            "INFO:tensorflow:loss = 0.01555934, step = 5701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.93\n",
            "INFO:tensorflow:loss = 0.013886055, step = 5801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.832\n",
            "INFO:tensorflow:loss = 0.014830123, step = 5901 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 691.223\n",
            "INFO:tensorflow:loss = 0.011103302, step = 6001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.09\n",
            "INFO:tensorflow:loss = 0.014291522, step = 6101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.649\n",
            "INFO:tensorflow:loss = 0.014969161, step = 6201 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.896\n",
            "INFO:tensorflow:loss = 0.017628621, step = 6301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.976\n",
            "INFO:tensorflow:loss = 0.01932235, step = 6401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.75\n",
            "INFO:tensorflow:loss = 0.02110466, step = 6501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.862\n",
            "INFO:tensorflow:loss = 0.021267856, step = 6601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.127\n",
            "INFO:tensorflow:loss = 0.016991803, step = 6701 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.335\n",
            "INFO:tensorflow:loss = 0.01868921, step = 6801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.956\n",
            "INFO:tensorflow:loss = 0.012755062, step = 6901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.262\n",
            "INFO:tensorflow:loss = 0.011905517, step = 7001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.685\n",
            "INFO:tensorflow:loss = 0.012925994, step = 7101 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 704.294\n",
            "INFO:tensorflow:loss = 0.008286726, step = 7201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.83\n",
            "INFO:tensorflow:loss = 0.0133297155, step = 7301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.121\n",
            "INFO:tensorflow:loss = 0.015159283, step = 7401 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.961\n",
            "INFO:tensorflow:loss = 0.012183841, step = 7501 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.438\n",
            "INFO:tensorflow:loss = 0.016813993, step = 7601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.975\n",
            "INFO:tensorflow:loss = 0.019142505, step = 7701 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.678\n",
            "INFO:tensorflow:loss = 0.01723872, step = 7801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.053\n",
            "INFO:tensorflow:loss = 0.018779907, step = 7901 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.113\n",
            "INFO:tensorflow:loss = 0.018468097, step = 8001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.672\n",
            "INFO:tensorflow:loss = 0.01579348, step = 8101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.359\n",
            "INFO:tensorflow:loss = 0.0154603645, step = 8201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.795\n",
            "INFO:tensorflow:loss = 0.012700335, step = 8301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.671\n",
            "INFO:tensorflow:loss = 0.014623591, step = 8401 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.87\n",
            "INFO:tensorflow:loss = 0.022899637, step = 8501 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.541\n",
            "INFO:tensorflow:loss = 0.014095992, step = 8601 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.773\n",
            "INFO:tensorflow:loss = 0.020272702, step = 8701 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.279\n",
            "INFO:tensorflow:loss = 0.01704034, step = 8801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.575\n",
            "INFO:tensorflow:loss = 0.018411469, step = 8901 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.354\n",
            "INFO:tensorflow:loss = 0.014473254, step = 9001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.677\n",
            "INFO:tensorflow:loss = 0.015509395, step = 9101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.889\n",
            "INFO:tensorflow:loss = 0.015280859, step = 9201 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.056\n",
            "INFO:tensorflow:loss = 0.0157369, step = 9301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.295\n",
            "INFO:tensorflow:loss = 0.01250763, step = 9401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.351\n",
            "INFO:tensorflow:loss = 0.016543936, step = 9501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.409\n",
            "INFO:tensorflow:loss = 0.020050004, step = 9601 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.666\n",
            "INFO:tensorflow:loss = 0.016106375, step = 9701 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.722\n",
            "INFO:tensorflow:loss = 0.015282985, step = 9801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.347\n",
            "INFO:tensorflow:loss = 0.021655936, step = 9901 (0.165 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_collision_regression_trained_model_mo_day_temp_min/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.014108546.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_mo_day_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "DNNRegression has RMSE of 126.24728827413102\n",
            "Just using average = 564.9756990679094 has RMSE of 135.34001077774784\n",
            "\n",
            "Great! Your DNN Regression model performs better than finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5rfeLsjUHsn"
      },
      "source": [
        "2.2.1 Deep Neural Network Validation Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY2JhO-GUHsn",
        "outputId": "c127e5fb-d3cf-4797-bcbb-ed81ad6a2df5"
      },
      "source": [
        "# Perform validation assessment of DNN model using test values reserved from original dataset\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_mo_day_temp_min', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "# Use test values reserved from original data set\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1afa8eda0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_mo_day_temp_min', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_mo_day_temp_min/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [625.5722  480.72522 582.30396 645.7911  588.89233 598.76587 587.9207\n",
            " 594.6081  643.9663  553.4099  598.22217 468.9862  564.81085 505.62393\n",
            " 460.35498 613.55273 625.4856  606.01733 611.13226 610.7002  635.56555\n",
            " 639.14514 592.35    604.4016  591.1399  578.84906 464.3945  546.489\n",
            " 516.60114 484.18774 619.42957 612.5802  550.2862  598.75385 528.4714\n",
            " 633.221   507.21533 514.63824 546.67664 608.85895 497.57294 581.91394\n",
            " 615.41077 483.75345 466.8795  496.98663 605.286   523.4495  627.949\n",
            " 562.67096]\n",
            "\n",
            "==== Target Collision Values ==== [322 518 451 645 579 653 607 264 451 492 613 393 558 529 384 538 683 455\n",
            " 744 591 672 598 650 641 592 504 422 577 530 374 594 667 557 510 542 438\n",
            " 572 459 531 517 312 729 591 166 411 515 830 502 309 700]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoBnvQ8ZUHsn"
      },
      "source": [
        "From the results of the validation test, it can be seen that like the previous models, the DNN model struggles to accurately predict outlier values which are either unusually large or small, but it can be seen that some of the predicted values are a close match to the target values overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBvdvCNpUHso"
      },
      "source": [
        "# **2.3 Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MznWICaBUHso"
      },
      "source": [
        "From the results of the linear and DNN models, it was observed that the linear model performed worse than just finding the average number of collisions using a mean value on most runs, but overall, the DNN model performed better than finding the average.\r\n",
        "\r\n",
        "The choice of an improved dataset and selecting day, month and minimum temperature, may have contributed to an improved model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1EuZyqHLics"
      },
      "source": [
        "#**3. Wind and Air Pressure Factors**\r\n",
        "\r\n",
        "I will now investigate if air pressure and windspeed factors, changes the performance of the models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QerdQ3dWLic0"
      },
      "source": [
        "# Import pandas to allow creation of data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Create data frame from github csv file\n",
        "source_dataframe = pd.read_csv('https://raw.githubusercontent.com/15014370uhi/15014370_DataAnalytics/master/bq-cleansed_weather_reduced_assignment_1.csv', index_col=0,);"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-xNBSoRLic1",
        "outputId": "e465394c-4e25-43f7-e105-27cbdac74f60"
      },
      "source": [
        "# Check that correct data is present\n",
        "print(source_dataframe) "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  da  day  temp  dewp  ...  mxpsd   max   min  prcp  NUM_COLLISIONS\n",
            "year                           ...                                         \n",
            "2012   7   1    7  83.6  63.0  ...    9.9  93.0  66.0  0.00             538\n",
            "2012   7   2    1  80.3  54.1  ...   15.0  88.0  66.9  0.00             564\n",
            "2012   7   3    2  79.8  56.7  ...   12.0  88.0  63.0  0.00             664\n",
            "2012   7   4    3  81.8  65.6  ...   11.1  91.0  68.0  0.06             432\n",
            "2012   7   6    5  81.9  62.3  ...    9.9  91.0  66.9  0.00             638\n",
            "...   ..  ..  ...   ...   ...  ...    ...   ...   ...   ...             ...\n",
            "2020  12   1    2  58.1  54.3  ...   34.0  63.0  45.0  0.88             253\n",
            "2020  12   2    3  47.5  35.9  ...   22.9  63.0  42.1  0.59             204\n",
            "2020  12   3    4  45.1  32.4  ...   18.1  52.0  36.0  0.02             218\n",
            "2020  12   4    5  53.6  43.8  ...   18.1  59.0  36.0  0.00             319\n",
            "2020  12   5    6  51.9  48.9  ...   32.1  59.0  39.9  0.32             222\n",
            "\n",
            "[3054 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NwzNWMpLic1",
        "outputId": "2dbc63d1-3cd0-4df7-dd3b-18572fdd9d53"
      },
      "source": [
        "# Find the total length of data rows\r\n",
        "totalNumberOfRows = len(source_dataframe);\r\n",
        "print(totalNumberOfRows);"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT4nz29kLic1"
      },
      "source": [
        "# Import numpty to improve speed of math calculations\n",
        "import numpy as np"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNgL6cZWLic2"
      },
      "source": [
        "# Shuffle all source data\r\n",
        "source_dataframe = source_dataframe.iloc[np.random.permutation(len(source_dataframe))]; "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sFNCBRuLic2"
      },
      "source": [
        "# Number of rows to reserve for testing\r\n",
        "number_of_test_rows = 50"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaNBxCz7Lic2"
      },
      "source": [
        "# Store training data as (all rows - number_of_test_rows) of source data\n",
        "df_train = source_dataframe[:-number_of_test_rows];\n",
        "\n",
        "# Shuffle training data a second time\n",
        "df_train = df_train.iloc[np.random.permutation(len(df_train))]; \n",
        "\n",
        "# Store validation test data as last number_of_test_rows of rows of source data\n",
        "df_test = source_dataframe[-number_of_test_rows:];\n",
        "\n",
        "# Shuffle test data a second time\n",
        "df_test = df_test.iloc[np.random.permutation(len(df_test))];\n",
        "\n",
        "# Store only relevant columns of data for this model\n",
        "df_train = df_train.iloc[:, [5,7,8,12]]; \n",
        "df_test = df_test.iloc[:, [5,7,8,12]];\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-fXWSiZLic2",
        "outputId": "2d0bf0ba-cb3a-4484-b1e6-99289e5ab9ef"
      },
      "source": [
        "# Confirm training data is stored \r\n",
        "print(df_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         slp  wdsp  mxpsd  NUM_COLLISIONS\n",
            "year                                     \n",
            "2015  1019.2  15.4   21.0             742\n",
            "2017   999.6  12.9   19.0             729\n",
            "2014  1019.7   4.1    9.9             644\n",
            "2013  1011.3  13.0   24.1             701\n",
            "2016  1006.4  17.0   21.0             616\n",
            "...      ...   ...    ...             ...\n",
            "2017  1019.1   7.5   14.0             771\n",
            "2014  1018.6   6.9   13.0             639\n",
            "2019  1007.6  10.4   19.0             633\n",
            "2017  1021.4  14.1   20.0             541\n",
            "2013  1003.8  13.6   19.0             604\n",
            "\n",
            "[3004 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "921F3UFDLic2",
        "outputId": "6b0bfe71-6f0a-43aa-af51-a137ba5b1476"
      },
      "source": [
        "# Confirm test data rows are stored\r\n",
        "print(df_test);"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         slp  wdsp  mxpsd  NUM_COLLISIONS\n",
            "year                                     \n",
            "2017  1013.6  12.4   22.0             661\n",
            "2012  1023.9   3.0    8.9             511\n",
            "2014  1017.9  13.4   24.1             547\n",
            "2020  1011.2  15.0   22.9             191\n",
            "2013  1016.3  11.8   18.1             791\n",
            "2016  1020.4  13.1   22.0             702\n",
            "2012  1019.9   4.1    9.9             494\n",
            "2017  1028.6  17.1   25.1             703\n",
            "2016  1015.4  18.6   27.0             798\n",
            "2019  1019.3   9.1   18.1             580\n",
            "2018  1009.8  13.8   18.1             601\n",
            "2019  1021.8   7.8   17.1             445\n",
            "2015  1019.7   8.2   11.1             646\n",
            "2018  1028.8  14.5   17.1             494\n",
            "2020  1014.7   3.9    8.0             295\n",
            "2018  1025.8   9.8   12.0             654\n",
            "2018  1019.1   9.5   13.0             580\n",
            "2013  1018.1  12.5   19.0             570\n",
            "2019  1023.6   6.7   11.1             613\n",
            "2018  1010.6  13.9   20.0             746\n",
            "2017  1018.5   5.7   11.1             639\n",
            "2014  1014.7   7.0   18.1             589\n",
            "2018  1005.6  16.6   26.0             662\n",
            "2019  1026.1   7.6   12.0             448\n",
            "2018  1011.1  11.9   22.0             617\n",
            "2020  1034.5  13.4   26.0             225\n",
            "2018  1016.7  10.7   15.0             557\n",
            "2019  1035.1   5.2    8.9             520\n",
            "2019   999.3  21.7   28.0             530\n",
            "2015  1017.8   6.4    9.9             760\n",
            "2018  1026.8   7.2   14.0             568\n",
            "2012  1016.1   3.1    9.9             630\n",
            "2020  1020.2  10.4   12.0             299\n",
            "2017  1009.8  10.3   17.1             657\n",
            "2019  1013.8   8.8   17.1             395\n",
            "2015  1013.9  16.6   22.0             686\n",
            "2018  1008.6  16.1   24.1             629\n",
            "2014  1014.0  16.1   22.9             635\n",
            "2012  1010.6   3.3   15.0             574\n",
            "2018  1020.1   6.5   11.1             693\n",
            "2017  1013.7  11.4   15.0             537\n",
            "2015  1013.2   7.4   11.1             732\n",
            "2018  1013.2   9.8   15.9             721\n",
            "2013  1017.3   7.0   11.1             542\n",
            "2017  1012.6  15.0   21.0             606\n",
            "2015  1020.8  18.3   26.0             582\n",
            "2018  1014.2  11.4   15.9             465\n",
            "2013  1010.6   7.7   15.0             570\n",
            "2019  1024.6   7.6   13.0             587\n",
            "2018  1000.1  13.5   19.0             753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUGM8a0RLic3"
      },
      "source": [
        "# Select Predictor columns for training and testing data to be used to predict the outcome\n",
        "\n",
        "predictors_train = df_train.iloc[:, [0,1,2]];\n",
        "predictors_test = df_test.iloc[:,  [0,1,2]];"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC0KzR43Lic3",
        "outputId": "6b0b93d9-a771-4b6d-9b46-66b0f06c7ea5"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         slp  wdsp  mxpsd\n",
            "year                     \n",
            "2015  1019.2  15.4   21.0\n",
            "2017   999.6  12.9   19.0\n",
            "2014  1019.7   4.1    9.9\n",
            "2013  1011.3  13.0   24.1\n",
            "2016  1006.4  17.0   21.0\n",
            "...      ...   ...    ...\n",
            "2017  1019.1   7.5   14.0\n",
            "2014  1018.6   6.9   13.0\n",
            "2019  1007.6  10.4   19.0\n",
            "2017  1021.4  14.1   20.0\n",
            "2013  1003.8  13.6   19.0\n",
            "\n",
            "[3004 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa3lK6uELic3",
        "outputId": "504c77ec-3ae6-4028-d1f1-4a6869c00be1"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_test);"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         slp  wdsp  mxpsd\n",
            "year                     \n",
            "2017  1013.6  12.4   22.0\n",
            "2012  1023.9   3.0    8.9\n",
            "2014  1017.9  13.4   24.1\n",
            "2020  1011.2  15.0   22.9\n",
            "2013  1016.3  11.8   18.1\n",
            "2016  1020.4  13.1   22.0\n",
            "2012  1019.9   4.1    9.9\n",
            "2017  1028.6  17.1   25.1\n",
            "2016  1015.4  18.6   27.0\n",
            "2019  1019.3   9.1   18.1\n",
            "2018  1009.8  13.8   18.1\n",
            "2019  1021.8   7.8   17.1\n",
            "2015  1019.7   8.2   11.1\n",
            "2018  1028.8  14.5   17.1\n",
            "2020  1014.7   3.9    8.0\n",
            "2018  1025.8   9.8   12.0\n",
            "2018  1019.1   9.5   13.0\n",
            "2013  1018.1  12.5   19.0\n",
            "2019  1023.6   6.7   11.1\n",
            "2018  1010.6  13.9   20.0\n",
            "2017  1018.5   5.7   11.1\n",
            "2014  1014.7   7.0   18.1\n",
            "2018  1005.6  16.6   26.0\n",
            "2019  1026.1   7.6   12.0\n",
            "2018  1011.1  11.9   22.0\n",
            "2020  1034.5  13.4   26.0\n",
            "2018  1016.7  10.7   15.0\n",
            "2019  1035.1   5.2    8.9\n",
            "2019   999.3  21.7   28.0\n",
            "2015  1017.8   6.4    9.9\n",
            "2018  1026.8   7.2   14.0\n",
            "2012  1016.1   3.1    9.9\n",
            "2020  1020.2  10.4   12.0\n",
            "2017  1009.8  10.3   17.1\n",
            "2019  1013.8   8.8   17.1\n",
            "2015  1013.9  16.6   22.0\n",
            "2018  1008.6  16.1   24.1\n",
            "2014  1014.0  16.1   22.9\n",
            "2012  1010.6   3.3   15.0\n",
            "2018  1020.1   6.5   11.1\n",
            "2017  1013.7  11.4   15.0\n",
            "2015  1013.2   7.4   11.1\n",
            "2018  1013.2   9.8   15.9\n",
            "2013  1017.3   7.0   11.1\n",
            "2017  1012.6  15.0   21.0\n",
            "2015  1020.8  18.3   26.0\n",
            "2018  1014.2  11.4   15.9\n",
            "2013  1010.6   7.7   15.0\n",
            "2019  1024.6   7.6   13.0\n",
            "2018  1000.1  13.5   19.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjuHT7yGLic3"
      },
      "source": [
        "# Select target columns\n",
        "targets_train = df_train.iloc[:,3];\n",
        "\n",
        "# Select target columns\n",
        "targets_test = df_test.iloc[:,3];"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVQZYBnMLic3",
        "outputId": "8c243d28-4e41-4467-d28d-ab324df1f082"
      },
      "source": [
        "print(targets_train);"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2015    742\n",
            "2017    729\n",
            "2014    644\n",
            "2013    701\n",
            "2016    616\n",
            "       ... \n",
            "2017    771\n",
            "2014    639\n",
            "2019    633\n",
            "2017    541\n",
            "2013    604\n",
            "Name: NUM_COLLISIONS, Length: 3004, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoaHfXZELic3",
        "outputId": "cc0326a7-782e-4e64-b677-8550a06b436c"
      },
      "source": [
        "print(targets_test);"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2017    661\n",
            "2012    511\n",
            "2014    547\n",
            "2020    191\n",
            "2013    791\n",
            "2016    702\n",
            "2012    494\n",
            "2017    703\n",
            "2016    798\n",
            "2019    580\n",
            "2018    601\n",
            "2019    445\n",
            "2015    646\n",
            "2018    494\n",
            "2020    295\n",
            "2018    654\n",
            "2018    580\n",
            "2013    570\n",
            "2019    613\n",
            "2018    746\n",
            "2017    639\n",
            "2014    589\n",
            "2018    662\n",
            "2019    448\n",
            "2018    617\n",
            "2020    225\n",
            "2018    557\n",
            "2019    520\n",
            "2019    530\n",
            "2015    760\n",
            "2018    568\n",
            "2012    630\n",
            "2020    299\n",
            "2017    657\n",
            "2019    395\n",
            "2015    686\n",
            "2018    629\n",
            "2014    635\n",
            "2012    574\n",
            "2018    693\n",
            "2017    537\n",
            "2015    732\n",
            "2018    721\n",
            "2013    542\n",
            "2017    606\n",
            "2015    582\n",
            "2018    465\n",
            "2013    570\n",
            "2019    587\n",
            "2018    753\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPCkpy4Lic4"
      },
      "source": [
        "# Set scale value\n",
        "SCALE_NUM_COLLISIONS = 1000.0;"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbuuADbsLic4"
      },
      "source": [
        "# Get size of training set \n",
        "trainsize = int(len(df_train['NUM_COLLISIONS']));\n",
        "\n",
        "# Get size of test set \n",
        "testsize = int(len(df_test['NUM_COLLISIONS']));"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kyGFWSkLic4",
        "outputId": "8c17181d-8cae-409f-b2b3-6007f8293cae"
      },
      "source": [
        "print(trainsize);"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoDGQlyaLic4",
        "outputId": "887e801e-397c-4380-a5dd-84a3c118d78f"
      },
      "source": [
        "print(testsize);"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeGBmR6BLic4"
      },
      "source": [
        "\r\n",
        "# Define the number of predictor column input values\r\n",
        "nppredictors = len(predictors_train.columns);\r\n",
        "\r\n",
        "# Define the number of target column output values\r\n",
        "noutputs = 1;\r\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9-QeCFwLic4",
        "outputId": "e64aaba5-06ef-471d-8ac5-7b57144594f6"
      },
      "source": [
        "print(nppredictors)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAn62_FbLic4"
      },
      "source": [
        "# **3.1 Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4KQLlPvLic5",
        "outputId": "a1ffc9cb-424f-4d4d-f5bc-18969e9bd9da"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_windspeed', ignore_errors=True)\n",
        "   \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_windspeed', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Prints log to show start of training model\n",
        "print(\"starting to train...\\n\");\n",
        "\n",
        "# Train the model using predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Check predictions based on predictor values\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply Scale value to outputs\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE using predictions and targets\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nLinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store linear regressor value\n",
        "rmse_LR = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate mean value of Number of Collisions\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Number of Collision Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2));\n",
        "print('Just using an average = {0}, has RMSE of {1}'.format(avg, rmse)); \n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "if(rmse_LR < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your Linear Regression model performs better than finding average!');\n",
        "else: \n",
        "  print('\\nSorry! On this run, your model performs worse than just finding the average!');\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1af7d6198>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_windspeed', '_session_creation_timeout_secs': 7200}\n",
            "starting to train...\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_windspeed/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.35284722, step = 1\n",
            "INFO:tensorflow:global_step/sec: 799.437\n",
            "INFO:tensorflow:loss = 0.24335743, step = 101 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.26\n",
            "INFO:tensorflow:loss = 16.993755, step = 201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 920.157\n",
            "INFO:tensorflow:loss = 0.7530938, step = 301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1034.07\n",
            "INFO:tensorflow:loss = 0.017855465, step = 401 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.547\n",
            "INFO:tensorflow:loss = 0.015998185, step = 501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.973\n",
            "INFO:tensorflow:loss = 0.018891722, step = 601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.132\n",
            "INFO:tensorflow:loss = 0.015411159, step = 701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1019.23\n",
            "INFO:tensorflow:loss = 0.018104488, step = 801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.506\n",
            "INFO:tensorflow:loss = 0.02442759, step = 901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.94\n",
            "INFO:tensorflow:loss = 0.01686469, step = 1001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.726\n",
            "INFO:tensorflow:loss = 0.023994152, step = 1101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.732\n",
            "INFO:tensorflow:loss = 0.060794696, step = 1201 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.658\n",
            "INFO:tensorflow:loss = 40.612556, step = 1301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.76\n",
            "INFO:tensorflow:loss = 1.2055708, step = 1401 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.475\n",
            "INFO:tensorflow:loss = 0.01861852, step = 1501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.023\n",
            "INFO:tensorflow:loss = 0.02004917, step = 1601 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.437\n",
            "INFO:tensorflow:loss = 0.022066483, step = 1701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.83\n",
            "INFO:tensorflow:loss = 0.019468473, step = 1801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.264\n",
            "INFO:tensorflow:loss = 0.029272217, step = 1901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 912.466\n",
            "INFO:tensorflow:loss = 0.03726869, step = 2001 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.007\n",
            "INFO:tensorflow:loss = 0.025708139, step = 2101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.35\n",
            "INFO:tensorflow:loss = 0.024295527, step = 2201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.48\n",
            "INFO:tensorflow:loss = 0.14294823, step = 2301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.663\n",
            "INFO:tensorflow:loss = 2.557661, step = 2401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007.52\n",
            "INFO:tensorflow:loss = 0.028660338, step = 2501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.885\n",
            "INFO:tensorflow:loss = 0.28012747, step = 2601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.973\n",
            "INFO:tensorflow:loss = 43.117695, step = 2701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.595\n",
            "INFO:tensorflow:loss = 0.49459866, step = 2801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.63\n",
            "INFO:tensorflow:loss = 126.266594, step = 2901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.537\n",
            "INFO:tensorflow:loss = 3.8581457, step = 3001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.052\n",
            "INFO:tensorflow:loss = 1.0982739, step = 3101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.514\n",
            "INFO:tensorflow:loss = 17.162878, step = 3201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.87\n",
            "INFO:tensorflow:loss = 0.066288665, step = 3301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.685\n",
            "INFO:tensorflow:loss = 0.01864016, step = 3401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.59\n",
            "INFO:tensorflow:loss = 0.052857395, step = 3501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.984\n",
            "INFO:tensorflow:loss = 0.048820518, step = 3601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.153\n",
            "INFO:tensorflow:loss = 0.5417619, step = 3701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.822\n",
            "INFO:tensorflow:loss = 1.0387689, step = 3801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.341\n",
            "INFO:tensorflow:loss = 4.503866, step = 3901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.418\n",
            "INFO:tensorflow:loss = 1.1044701, step = 4001 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.245\n",
            "INFO:tensorflow:loss = 0.01992145, step = 4101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1026.71\n",
            "INFO:tensorflow:loss = 0.034925718, step = 4201 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.274\n",
            "INFO:tensorflow:loss = 0.020512082, step = 4301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.283\n",
            "INFO:tensorflow:loss = 0.6778056, step = 4401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.829\n",
            "INFO:tensorflow:loss = 0.16982993, step = 4501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.408\n",
            "INFO:tensorflow:loss = 15.027981, step = 4601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.657\n",
            "INFO:tensorflow:loss = 14.454504, step = 4701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.491\n",
            "INFO:tensorflow:loss = 0.02439364, step = 4801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.048\n",
            "INFO:tensorflow:loss = 0.016405119, step = 4901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.24\n",
            "INFO:tensorflow:loss = 0.01625449, step = 5001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.9\n",
            "INFO:tensorflow:loss = 0.019849256, step = 5101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.734\n",
            "INFO:tensorflow:loss = 0.018878639, step = 5201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.96\n",
            "INFO:tensorflow:loss = 0.021313043, step = 5301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.585\n",
            "INFO:tensorflow:loss = 0.018114865, step = 5401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 903.481\n",
            "INFO:tensorflow:loss = 0.020367444, step = 5501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.693\n",
            "INFO:tensorflow:loss = 0.019989846, step = 5601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.39\n",
            "INFO:tensorflow:loss = 0.048400357, step = 5701 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1058.98\n",
            "INFO:tensorflow:loss = 0.1477797, step = 5801 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.595\n",
            "INFO:tensorflow:loss = 0.6495973, step = 5901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1047.71\n",
            "INFO:tensorflow:loss = 0.16035312, step = 6001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.927\n",
            "INFO:tensorflow:loss = 30.611534, step = 6101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.097\n",
            "INFO:tensorflow:loss = 18.33138, step = 6201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.97\n",
            "INFO:tensorflow:loss = 18.875582, step = 6301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.678\n",
            "INFO:tensorflow:loss = 0.05873155, step = 6401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1031.03\n",
            "INFO:tensorflow:loss = 9.633839, step = 6501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.167\n",
            "INFO:tensorflow:loss = 0.017062193, step = 6601 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.733\n",
            "INFO:tensorflow:loss = 0.013567732, step = 6701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1051.84\n",
            "INFO:tensorflow:loss = 1.9812874, step = 6801 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.44\n",
            "INFO:tensorflow:loss = 5.6773133, step = 6901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1034.33\n",
            "INFO:tensorflow:loss = 0.08267725, step = 7001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.76\n",
            "INFO:tensorflow:loss = 5.691142, step = 7101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.034\n",
            "INFO:tensorflow:loss = 2.3155875, step = 7201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.235\n",
            "INFO:tensorflow:loss = 0.02842344, step = 7301 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.341\n",
            "INFO:tensorflow:loss = 0.05176616, step = 7401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.97\n",
            "INFO:tensorflow:loss = 0.02410657, step = 7501 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.235\n",
            "INFO:tensorflow:loss = 0.050321445, step = 7601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1039.99\n",
            "INFO:tensorflow:loss = 0.017836455, step = 7701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.917\n",
            "INFO:tensorflow:loss = 0.029082797, step = 7801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.643\n",
            "INFO:tensorflow:loss = 0.120815545, step = 7901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.556\n",
            "INFO:tensorflow:loss = 0.08048335, step = 8001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.012\n",
            "INFO:tensorflow:loss = 0.43821377, step = 8101 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.08\n",
            "INFO:tensorflow:loss = 2.2160416, step = 8201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.875\n",
            "INFO:tensorflow:loss = 11.25255, step = 8301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1013.51\n",
            "INFO:tensorflow:loss = 0.6051253, step = 8401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.37\n",
            "INFO:tensorflow:loss = 0.14144525, step = 8501 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.401\n",
            "INFO:tensorflow:loss = 0.019867914, step = 8601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.97\n",
            "INFO:tensorflow:loss = 0.032096427, step = 8701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.661\n",
            "INFO:tensorflow:loss = 0.28430942, step = 8801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.138\n",
            "INFO:tensorflow:loss = 0.38385093, step = 8901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.352\n",
            "INFO:tensorflow:loss = 6.5908747, step = 9001 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 1024.79\n",
            "INFO:tensorflow:loss = 60.34258, step = 9101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.277\n",
            "INFO:tensorflow:loss = 1.3451166, step = 9201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.605\n",
            "INFO:tensorflow:loss = 0.17436576, step = 9301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.26\n",
            "INFO:tensorflow:loss = 1.8653197, step = 9401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.889\n",
            "INFO:tensorflow:loss = 11.798497, step = 9501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.567\n",
            "INFO:tensorflow:loss = 0.13722497, step = 9601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.633\n",
            "INFO:tensorflow:loss = 0.033872098, step = 9701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.74\n",
            "INFO:tensorflow:loss = 0.021418981, step = 9801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.365\n",
            "INFO:tensorflow:loss = 0.017853778, step = 9901 (0.103 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_windspeed/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.17583567.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_windspeed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "LinearRegression has RMSE of 407.19810752772065\n",
            "Just using an average = 564.1274966711052, has RMSE of 135.3456936165717\n",
            "\n",
            "Sorry! On this run, your model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Mxs4tdLic5"
      },
      "source": [
        "**3.1.1 Linear Regression Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrcz1z6qLic5"
      },
      "source": [
        "Perform linear regression validation test using values from the original data set reserved for testing.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edLkaU8tLic5",
        "outputId": "56d1837b-ea6b-409d-a549-edb3b55feaca"
      },
      "source": [
        "\n",
        "# Perform linear regression validation test using values from the original data set reserved for testing.\n",
        "                                                                                                 \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_windspeed', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1af7e0668>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_windspeed', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_windspeed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [943.367   959.05414 946.4862  940.1124  947.00214 949.3984  954.77966\n",
            " 954.905   941.8209  950.61847 940.3893  953.57697 952.9979  957.887\n",
            " 950.5294  957.8778  951.5648  948.2133  957.06085 940.6248  952.68823\n",
            " 947.05493 933.68994 958.8523  941.2267  961.284   948.4836  968.6555\n",
            " 925.78357 952.118   959.13007 951.6025  952.5372  941.7473  945.9022\n",
            " 942.30927 937.0761  942.33813 945.22363 953.9056  945.5024  947.27423\n",
            " 945.32874 951.17175 941.8682  947.1288  945.7403  943.82635 957.22626\n",
            " 931.34204]\n",
            "\n",
            "==== Target Collision Values ==== [661 511 547 191 791 702 494 703 798 580 601 445 646 494 295 654 580 570\n",
            " 613 746 639 589 662 448 617 225 557 520 530 760 568 630 299 657 395 686\n",
            " 629 635 574 693 537 732 721 542 606 582 465 570 587 753]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdJPhC74Lic5"
      },
      "source": [
        "# **3.2 Deep Neural Network Regressor**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tphl-PIbLic6",
        "outputId": "52a3d9ab-d4a3-4019-9561-c2475c0ccff2"
      },
      "source": [
        "# Import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Required for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# Remove any previously saved training model training\n",
        "shutil.rmtree('/tmp/DNN_collision_regression_trained_model_windspeed', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_windspeed', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Print message to display start of training log\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model by passing predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE value to determine how well the model works using prediction and target values.\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nDNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store DNN regressoion value\n",
        "rmse_DNN = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate the mean of the Number of Collision Values.\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'])\n",
        "\n",
        "# Calculate RMSE using COLLISION Values and the mean of all target values to determine\n",
        "# if the DNN model is better than calculating the mean value.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Output success or failure message for this model\n",
        "if(rmse_DNN < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your DNN Regression model performs better than finding the average!'); # Success\n",
        "else: \n",
        "  print('\\nSorry! But on this run, your DNN Regression model performs worse than just finding the average!'); # Failure\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1af78ebe0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_windspeed', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_collision_regression_trained_model_windspeed/model.ckpt.\n",
            "INFO:tensorflow:loss = 10766.925, step = 1\n",
            "INFO:tensorflow:global_step/sec: 506.018\n",
            "INFO:tensorflow:loss = 0.0832615, step = 101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.599\n",
            "INFO:tensorflow:loss = 0.22702704, step = 201 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.367\n",
            "INFO:tensorflow:loss = 0.047250822, step = 301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.822\n",
            "INFO:tensorflow:loss = 0.043689556, step = 401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.347\n",
            "INFO:tensorflow:loss = 0.04078661, step = 501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.92\n",
            "INFO:tensorflow:loss = 0.03351219, step = 601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 711.66\n",
            "INFO:tensorflow:loss = 0.025231913, step = 701 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.877\n",
            "INFO:tensorflow:loss = 0.039395098, step = 801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.022\n",
            "INFO:tensorflow:loss = 0.030794498, step = 901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.346\n",
            "INFO:tensorflow:loss = 0.03291841, step = 1001 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.871\n",
            "INFO:tensorflow:loss = 0.023006197, step = 1101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.29\n",
            "INFO:tensorflow:loss = 0.022461053, step = 1201 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.444\n",
            "INFO:tensorflow:loss = 0.02652413, step = 1301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.397\n",
            "INFO:tensorflow:loss = 0.022815932, step = 1401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.309\n",
            "INFO:tensorflow:loss = 0.032610275, step = 1501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.934\n",
            "INFO:tensorflow:loss = 0.016544001, step = 1601 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.065\n",
            "INFO:tensorflow:loss = 0.02226879, step = 1701 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.823\n",
            "INFO:tensorflow:loss = 0.022112701, step = 1801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.221\n",
            "INFO:tensorflow:loss = 0.026504748, step = 1901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.295\n",
            "INFO:tensorflow:loss = 0.020359077, step = 2001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.896\n",
            "INFO:tensorflow:loss = 0.03050677, step = 2101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.763\n",
            "INFO:tensorflow:loss = 0.07086726, step = 2201 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.595\n",
            "INFO:tensorflow:loss = 0.0456844, step = 2301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.809\n",
            "INFO:tensorflow:loss = 0.033638176, step = 2401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.473\n",
            "INFO:tensorflow:loss = 0.025909891, step = 2501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.192\n",
            "INFO:tensorflow:loss = 0.017411273, step = 2601 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.37\n",
            "INFO:tensorflow:loss = 0.01891848, step = 2701 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.104\n",
            "INFO:tensorflow:loss = 0.026533356, step = 2801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.98\n",
            "INFO:tensorflow:loss = 0.037016556, step = 2901 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.581\n",
            "INFO:tensorflow:loss = 0.02435616, step = 3001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.712\n",
            "INFO:tensorflow:loss = 0.061480496, step = 3101 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.558\n",
            "INFO:tensorflow:loss = 0.14993289, step = 3201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.844\n",
            "INFO:tensorflow:loss = 0.06632044, step = 3301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.074\n",
            "INFO:tensorflow:loss = 0.112026215, step = 3401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.999\n",
            "INFO:tensorflow:loss = 0.041302383, step = 3501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.9\n",
            "INFO:tensorflow:loss = 0.020387981, step = 3601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.935\n",
            "INFO:tensorflow:loss = 0.3507617, step = 3701 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.62\n",
            "INFO:tensorflow:loss = 0.06613441, step = 3801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.523\n",
            "INFO:tensorflow:loss = 0.030705513, step = 3901 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.279\n",
            "INFO:tensorflow:loss = 0.03885963, step = 4001 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.325\n",
            "INFO:tensorflow:loss = 0.031511523, step = 4101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.696\n",
            "INFO:tensorflow:loss = 0.1002119, step = 4201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.061\n",
            "INFO:tensorflow:loss = 0.13576904, step = 4301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.472\n",
            "INFO:tensorflow:loss = 0.048039794, step = 4401 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.747\n",
            "INFO:tensorflow:loss = 0.05933527, step = 4501 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.904\n",
            "INFO:tensorflow:loss = 0.046425063, step = 4601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.311\n",
            "INFO:tensorflow:loss = 0.017574929, step = 4701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.35\n",
            "INFO:tensorflow:loss = 0.01675729, step = 4801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.18\n",
            "INFO:tensorflow:loss = 0.26452988, step = 4901 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 691.308\n",
            "INFO:tensorflow:loss = 0.026154071, step = 5001 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 697.28\n",
            "INFO:tensorflow:loss = 0.022046452, step = 5101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.308\n",
            "INFO:tensorflow:loss = 0.017701779, step = 5201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.749\n",
            "INFO:tensorflow:loss = 0.022392217, step = 5301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.34\n",
            "INFO:tensorflow:loss = 0.06413784, step = 5401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.879\n",
            "INFO:tensorflow:loss = 0.02483391, step = 5501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.373\n",
            "INFO:tensorflow:loss = 0.021890031, step = 5601 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.484\n",
            "INFO:tensorflow:loss = 0.020969369, step = 5701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.795\n",
            "INFO:tensorflow:loss = 0.020387117, step = 5801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.781\n",
            "INFO:tensorflow:loss = 0.02440417, step = 5901 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.187\n",
            "INFO:tensorflow:loss = 0.023759209, step = 6001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.82\n",
            "INFO:tensorflow:loss = 0.015687708, step = 6101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.005\n",
            "INFO:tensorflow:loss = 0.040985353, step = 6201 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.512\n",
            "INFO:tensorflow:loss = 0.024893962, step = 6301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 697.737\n",
            "INFO:tensorflow:loss = 0.02418151, step = 6401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.042\n",
            "INFO:tensorflow:loss = 0.053531185, step = 6501 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.865\n",
            "INFO:tensorflow:loss = 0.015487332, step = 6601 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.668\n",
            "INFO:tensorflow:loss = 0.013539672, step = 6701 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.288\n",
            "INFO:tensorflow:loss = 0.018759798, step = 6801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.638\n",
            "INFO:tensorflow:loss = 0.029741142, step = 6901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.897\n",
            "INFO:tensorflow:loss = 0.053389437, step = 7001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.328\n",
            "INFO:tensorflow:loss = 0.0414147, step = 7101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.895\n",
            "INFO:tensorflow:loss = 0.04470991, step = 7201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.206\n",
            "INFO:tensorflow:loss = 0.021624867, step = 7301 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.831\n",
            "INFO:tensorflow:loss = 0.018469423, step = 7401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.053\n",
            "INFO:tensorflow:loss = 0.025263563, step = 7501 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.225\n",
            "INFO:tensorflow:loss = 0.020740923, step = 7601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.336\n",
            "INFO:tensorflow:loss = 0.017492177, step = 7701 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.867\n",
            "INFO:tensorflow:loss = 0.029043708, step = 7801 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.545\n",
            "INFO:tensorflow:loss = 0.017171845, step = 7901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.51\n",
            "INFO:tensorflow:loss = 0.034729548, step = 8001 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.303\n",
            "INFO:tensorflow:loss = 0.022068914, step = 8101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.453\n",
            "INFO:tensorflow:loss = 0.02000396, step = 8201 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.706\n",
            "INFO:tensorflow:loss = 0.020393398, step = 8301 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.619\n",
            "INFO:tensorflow:loss = 0.020079609, step = 8401 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.389\n",
            "INFO:tensorflow:loss = 0.022148103, step = 8501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.237\n",
            "INFO:tensorflow:loss = 0.025410827, step = 8601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.275\n",
            "INFO:tensorflow:loss = 0.02143953, step = 8701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.117\n",
            "INFO:tensorflow:loss = 0.016681194, step = 8801 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.352\n",
            "INFO:tensorflow:loss = 0.017470112, step = 8901 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.491\n",
            "INFO:tensorflow:loss = 0.015898472, step = 9001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.102\n",
            "INFO:tensorflow:loss = 0.02491518, step = 9101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.746\n",
            "INFO:tensorflow:loss = 0.03612063, step = 9201 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.922\n",
            "INFO:tensorflow:loss = 0.021627545, step = 9301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.841\n",
            "INFO:tensorflow:loss = 0.020325093, step = 9401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.287\n",
            "INFO:tensorflow:loss = 0.028544184, step = 9501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.875\n",
            "INFO:tensorflow:loss = 0.020272445, step = 9601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.077\n",
            "INFO:tensorflow:loss = 0.020392023, step = 9701 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.97\n",
            "INFO:tensorflow:loss = 0.021159071, step = 9801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.215\n",
            "INFO:tensorflow:loss = 0.01682779, step = 9901 (0.151 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_collision_regression_trained_model_windspeed/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.014579406.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_windspeed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "DNNRegression has RMSE of 137.40405526183667\n",
            "Just using average = 564.1274966711052 has RMSE of 135.3456936165717\n",
            "\n",
            "Sorry! But on this run, your DNN Regression model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbKzNZieLic6"
      },
      "source": [
        "**3.2.1 Deep Neural Network Validation Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ESgy32JLic6",
        "outputId": "08952c0f-c8f9-4edb-81a3-6721952d3638"
      },
      "source": [
        "# Perform validation assessment of DNN model using test values reserved from original dataset\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_windspeed', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "# Use test values reserved from original data set\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1af79b0f0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_windspeed', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_windspeed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [580.50934 581.4401  581.6142  578.6224  582.3306  583.0055  580.44055\n",
            " 584.5997  578.60156 581.72815 579.124   581.99207 583.1402  586.6291\n",
            " 578.79047 586.48035 583.3666  582.7037  583.52057 579.13855 580.7762\n",
            " 578.3431  575.4523  584.9281  579.5775  587.96173 582.78864 587.4713\n",
            " 571.0835  581.3679  584.3429  578.2017  584.75415 579.2156  579.6351\n",
            " 579.3368  577.0753  579.4008  574.7985  582.00665 581.86206 580.0025\n",
            " 580.49255 581.29626 579.45355 580.99097 581.93274 578.1364  584.06683\n",
            " 575.2175 ]\n",
            "\n",
            "==== Target Collision Values ==== [661 511 547 191 791 702 494 703 798 580 601 445 646 494 295 654 580 570\n",
            " 613 746 639 589 662 448 617 225 557 520 530 760 568 630 299 657 395 686\n",
            " 629 635 574 693 537 732 721 542 606 582 465 570 587 753]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMBEhtH9Lic6"
      },
      "source": [
        "From the results of the validation test, it can be seen that many of the predicted values are a close match to the target values, although some of the higher target values were under-estimated by the DNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wukr1JN1Lic6"
      },
      "source": [
        "# **3.3 Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6BIwjYNLic7"
      },
      "source": [
        "From the results of the linear and DNN models, we can see that the linear model performed worse than just finding the average number of collisions using a mean value, but overall, the DNN model performed better than finding the average.\r\n",
        "\r\n",
        "The DNN model in this case is a good candidate for use as a predictive tool for collision numbers and to inform emergency services in New York city."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aqw2O70QPxR"
      },
      "source": [
        "#**4. Dew Point, Visibility and Precipitation**\r\n",
        "\r\n",
        "I will now investigate if dew point, visibility and precipitation changes the performance of the models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1qpsDyQPxW"
      },
      "source": [
        "# Import pandas to allow creation of data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Create data frame from github csv file\n",
        "source_dataframe = pd.read_csv('https://raw.githubusercontent.com/15014370uhi/15014370_DataAnalytics/master/bq-cleansed_weather_reduced_assignment_1.csv', index_col=0,);"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntYK-_dCQPxX",
        "outputId": "816a1d2e-7cfe-4bb4-ebe2-cced76ea5b13"
      },
      "source": [
        "# Check that correct data is present\n",
        "print(source_dataframe) "
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  da  day  temp  dewp  ...  mxpsd   max   min  prcp  NUM_COLLISIONS\n",
            "year                           ...                                         \n",
            "2012   7   1    7  83.6  63.0  ...    9.9  93.0  66.0  0.00             538\n",
            "2012   7   2    1  80.3  54.1  ...   15.0  88.0  66.9  0.00             564\n",
            "2012   7   3    2  79.8  56.7  ...   12.0  88.0  63.0  0.00             664\n",
            "2012   7   4    3  81.8  65.6  ...   11.1  91.0  68.0  0.06             432\n",
            "2012   7   6    5  81.9  62.3  ...    9.9  91.0  66.9  0.00             638\n",
            "...   ..  ..  ...   ...   ...  ...    ...   ...   ...   ...             ...\n",
            "2020  12   1    2  58.1  54.3  ...   34.0  63.0  45.0  0.88             253\n",
            "2020  12   2    3  47.5  35.9  ...   22.9  63.0  42.1  0.59             204\n",
            "2020  12   3    4  45.1  32.4  ...   18.1  52.0  36.0  0.02             218\n",
            "2020  12   4    5  53.6  43.8  ...   18.1  59.0  36.0  0.00             319\n",
            "2020  12   5    6  51.9  48.9  ...   32.1  59.0  39.9  0.32             222\n",
            "\n",
            "[3054 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiC-9hcKQPxX",
        "outputId": "c4b2e4f6-21a3-4ac9-ec4a-2658aa0424ef"
      },
      "source": [
        "# Find the total length of data rows\r\n",
        "totalNumberOfRows = len(source_dataframe);\r\n",
        "print(totalNumberOfRows);"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuSOUAZDQPxX"
      },
      "source": [
        "# Import numpty to improve speed of math calculations\n",
        "import numpy as np"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v-M7q9QQPxY"
      },
      "source": [
        "# Shuffle all source data\r\n",
        "source_dataframe = source_dataframe.iloc[np.random.permutation(len(source_dataframe))]; "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0jb-GurQPxY"
      },
      "source": [
        "# Number of rows to reserve for testing\r\n",
        "number_of_test_rows = 50"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGozbAoxQPxY"
      },
      "source": [
        "# Store training data as (all rows - number_of_test_rows) of source data\n",
        "df_train = source_dataframe[:-number_of_test_rows];\n",
        "\n",
        "# Shuffle training data a second time\n",
        "df_train = df_train.iloc[np.random.permutation(len(df_train))]; \n",
        "\n",
        "# Store validation test data as last number_of_test_rows of rows of source data\n",
        "df_test = source_dataframe[-number_of_test_rows:];\n",
        "\n",
        "# Shuffle test data a second time\n",
        "df_test = df_test.iloc[np.random.permutation(len(df_test))];\n",
        "\n",
        "# Store only relevant columns of data for this model\n",
        "df_train = df_train.iloc[:, [4,6,11,12]]; \n",
        "df_test = df_test.iloc[:, [4,6,11,12]];\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egN0p_KNQPxY",
        "outputId": "ff7a471d-2a9b-4561-a938-a6d2f2d0877b"
      },
      "source": [
        "# Confirm training data is stored \r\n",
        "print(df_train)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      dewp  visib  prcp  NUM_COLLISIONS\n",
            "year                                   \n",
            "2018  38.5   10.0  0.00             610\n",
            "2012  45.1    7.0  0.00             526\n",
            "2015  31.4   10.0  0.00             443\n",
            "2013  51.0    5.7  0.00             698\n",
            "2016  55.8    6.5  0.00             767\n",
            "...    ...    ...   ...             ...\n",
            "2018  21.7   10.0  0.01             494\n",
            "2018  31.7    9.1  0.00             668\n",
            "2018  56.7   10.0  0.00             700\n",
            "2012  32.1    9.3  0.00             480\n",
            "2014   8.0   10.0  0.00             547\n",
            "\n",
            "[3004 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brUcUhprQPxY",
        "outputId": "4cd81e17-f287-46d8-f7e4-3c8f19ef632c"
      },
      "source": [
        "# Confirm test data rows are stored\r\n",
        "print(df_test);"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      dewp  visib  prcp  NUM_COLLISIONS\n",
            "year                                   \n",
            "2014  44.2    6.6  0.03             732\n",
            "2019  60.1    5.6  0.13             734\n",
            "2019  34.9    9.6  0.00             510\n",
            "2013  32.9   10.0  0.00             626\n",
            "2019  16.2   10.0  0.00             562\n",
            "2016  49.8    5.6  0.13             649\n",
            "2017  63.7    8.8  0.00             747\n",
            "2013  11.3   10.0  0.00             648\n",
            "2014  61.5    8.2  0.11             662\n",
            "2020  53.3    7.0  0.00             198\n",
            "2018  32.9   10.0  0.00             629\n",
            "2013  29.2    9.8  0.26             600\n",
            "2015  55.4    8.0  0.00             389\n",
            "2014  52.3    9.3  0.00             607\n",
            "2015  64.4    8.8  0.00             598\n",
            "2014  10.5   10.0  0.00             474\n",
            "2015  33.8   10.0  0.00             628\n",
            "2014  48.1    8.1  0.15             546\n",
            "2015  68.8    9.5  0.00             552\n",
            "2015  69.6    9.0  0.00             614\n",
            "2016  24.3   10.0  0.00             482\n",
            "2012  71.3    7.6  0.00             617\n",
            "2014  60.8    9.1  0.02             625\n",
            "2014  61.3    9.9  0.00             538\n",
            "2014  10.4    6.3  0.02             649\n",
            "2016  14.7    8.1  0.01             597\n",
            "2015  68.1    9.2  0.30             606\n",
            "2020  41.9    3.7  0.48             190\n",
            "2013  67.1    6.5  0.02             597\n",
            "2015  38.5    5.0  0.55             565\n",
            "2020  69.3    2.1  0.43             362\n",
            "2014  57.0    7.1  0.00             528\n",
            "2015  11.0    8.1  0.04             757\n",
            "2018  -0.5   10.0  0.00             476\n",
            "2014  33.6    5.3  0.06             960\n",
            "2020  46.2    9.1  0.00             173\n",
            "2015  68.7    9.7  0.01             595\n",
            "2014  54.0    9.2  0.01             719\n",
            "2020  52.1   10.0  0.00             264\n",
            "2019  59.3    3.0  0.12             697\n",
            "2014  64.4    3.5  0.01             670\n",
            "2018  72.1    6.3  0.00             703\n",
            "2016  35.4   10.0  0.01             534\n",
            "2016  58.9    3.5  0.01             629\n",
            "2017  44.2   10.0  0.04             696\n",
            "2016  40.4    6.5  0.16             665\n",
            "2017  48.5   10.0  0.20             757\n",
            "2017  47.5    8.4  0.01             675\n",
            "2014  46.6   10.0  0.00             643\n",
            "2018  53.6   10.0  0.00             672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbJjIA-ZQPxY"
      },
      "source": [
        "# Select Predictor columns for training and testing data to be used to predict the outcome\n",
        "\n",
        "predictors_train = df_train.iloc[:, [0,1,2]];\n",
        "predictors_test = df_test.iloc[:,  [0,1,2]];"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZQWiIayQPxZ",
        "outputId": "b85a3d83-f839-45d7-f37f-90014f9cf4f0"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_train)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      dewp  visib  prcp\n",
            "year                   \n",
            "2018  38.5   10.0  0.00\n",
            "2012  45.1    7.0  0.00\n",
            "2015  31.4   10.0  0.00\n",
            "2013  51.0    5.7  0.00\n",
            "2016  55.8    6.5  0.00\n",
            "...    ...    ...   ...\n",
            "2018  21.7   10.0  0.01\n",
            "2018  31.7    9.1  0.00\n",
            "2018  56.7   10.0  0.00\n",
            "2012  32.1    9.3  0.00\n",
            "2014   8.0   10.0  0.00\n",
            "\n",
            "[3004 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szksqJzLQPxZ",
        "outputId": "008f6b58-4b26-4477-ddf9-e35606e227c2"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_test);"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      dewp  visib  prcp\n",
            "year                   \n",
            "2014  44.2    6.6  0.03\n",
            "2019  60.1    5.6  0.13\n",
            "2019  34.9    9.6  0.00\n",
            "2013  32.9   10.0  0.00\n",
            "2019  16.2   10.0  0.00\n",
            "2016  49.8    5.6  0.13\n",
            "2017  63.7    8.8  0.00\n",
            "2013  11.3   10.0  0.00\n",
            "2014  61.5    8.2  0.11\n",
            "2020  53.3    7.0  0.00\n",
            "2018  32.9   10.0  0.00\n",
            "2013  29.2    9.8  0.26\n",
            "2015  55.4    8.0  0.00\n",
            "2014  52.3    9.3  0.00\n",
            "2015  64.4    8.8  0.00\n",
            "2014  10.5   10.0  0.00\n",
            "2015  33.8   10.0  0.00\n",
            "2014  48.1    8.1  0.15\n",
            "2015  68.8    9.5  0.00\n",
            "2015  69.6    9.0  0.00\n",
            "2016  24.3   10.0  0.00\n",
            "2012  71.3    7.6  0.00\n",
            "2014  60.8    9.1  0.02\n",
            "2014  61.3    9.9  0.00\n",
            "2014  10.4    6.3  0.02\n",
            "2016  14.7    8.1  0.01\n",
            "2015  68.1    9.2  0.30\n",
            "2020  41.9    3.7  0.48\n",
            "2013  67.1    6.5  0.02\n",
            "2015  38.5    5.0  0.55\n",
            "2020  69.3    2.1  0.43\n",
            "2014  57.0    7.1  0.00\n",
            "2015  11.0    8.1  0.04\n",
            "2018  -0.5   10.0  0.00\n",
            "2014  33.6    5.3  0.06\n",
            "2020  46.2    9.1  0.00\n",
            "2015  68.7    9.7  0.01\n",
            "2014  54.0    9.2  0.01\n",
            "2020  52.1   10.0  0.00\n",
            "2019  59.3    3.0  0.12\n",
            "2014  64.4    3.5  0.01\n",
            "2018  72.1    6.3  0.00\n",
            "2016  35.4   10.0  0.01\n",
            "2016  58.9    3.5  0.01\n",
            "2017  44.2   10.0  0.04\n",
            "2016  40.4    6.5  0.16\n",
            "2017  48.5   10.0  0.20\n",
            "2017  47.5    8.4  0.01\n",
            "2014  46.6   10.0  0.00\n",
            "2018  53.6   10.0  0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Qpw6--QPxZ"
      },
      "source": [
        "# Select target columns\n",
        "targets_train = df_train.iloc[:,3];\n",
        "\n",
        "# Select target columns\n",
        "targets_test = df_test.iloc[:,3];"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9uUh-M0QPxZ",
        "outputId": "bb876269-0b72-4709-f602-c467183c930a"
      },
      "source": [
        "print(targets_train);"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2018    610\n",
            "2012    526\n",
            "2015    443\n",
            "2013    698\n",
            "2016    767\n",
            "       ... \n",
            "2018    494\n",
            "2018    668\n",
            "2018    700\n",
            "2012    480\n",
            "2014    547\n",
            "Name: NUM_COLLISIONS, Length: 3004, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N76O6ZQVQPxZ",
        "outputId": "19e9dd87-7456-4433-ac01-1ff14d570fb1"
      },
      "source": [
        "print(targets_test);"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2014    732\n",
            "2019    734\n",
            "2019    510\n",
            "2013    626\n",
            "2019    562\n",
            "2016    649\n",
            "2017    747\n",
            "2013    648\n",
            "2014    662\n",
            "2020    198\n",
            "2018    629\n",
            "2013    600\n",
            "2015    389\n",
            "2014    607\n",
            "2015    598\n",
            "2014    474\n",
            "2015    628\n",
            "2014    546\n",
            "2015    552\n",
            "2015    614\n",
            "2016    482\n",
            "2012    617\n",
            "2014    625\n",
            "2014    538\n",
            "2014    649\n",
            "2016    597\n",
            "2015    606\n",
            "2020    190\n",
            "2013    597\n",
            "2015    565\n",
            "2020    362\n",
            "2014    528\n",
            "2015    757\n",
            "2018    476\n",
            "2014    960\n",
            "2020    173\n",
            "2015    595\n",
            "2014    719\n",
            "2020    264\n",
            "2019    697\n",
            "2014    670\n",
            "2018    703\n",
            "2016    534\n",
            "2016    629\n",
            "2017    696\n",
            "2016    665\n",
            "2017    757\n",
            "2017    675\n",
            "2014    643\n",
            "2018    672\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFiPOMM4QPxZ"
      },
      "source": [
        "# Set scale value\n",
        "SCALE_NUM_COLLISIONS = 1000.0;"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJX4IPU1QPxZ"
      },
      "source": [
        "# Get size of training set \n",
        "trainsize = int(len(df_train['NUM_COLLISIONS']));\n",
        "\n",
        "# Get size of test set \n",
        "testsize = int(len(df_test['NUM_COLLISIONS']));"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnGM1Xx5QPxa",
        "outputId": "6b38f395-0b34-4307-ae1c-cb867cd32e9f"
      },
      "source": [
        "print(trainsize);"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAhnUHhFQPxa",
        "outputId": "10687fe3-a738-4178-d5b8-3576ded3bfe3"
      },
      "source": [
        "print(testsize);"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpsq6TnKQPxa"
      },
      "source": [
        "\r\n",
        "# Define the number of predictor column input values\r\n",
        "nppredictors = len(predictors_train.columns);\r\n",
        "\r\n",
        "# Define the number of target column output values\r\n",
        "noutputs = 1;\r\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JnLor60QPxa",
        "outputId": "dd6ac51a-b8e1-46b8-98f8-b6573b17841c"
      },
      "source": [
        "print(nppredictors)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSrRUEhwQPxa"
      },
      "source": [
        "# **4.1 Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTSomhUQPxa",
        "outputId": "7ee2b026-f3d2-4f75-ea52-93d87ad8895e"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_dew_visib_precip', ignore_errors=True)\n",
        "   \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dew_visib_precip', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Prints log to show start of training model\n",
        "print(\"starting to train...\\n\");\n",
        "\n",
        "# Train the model using predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Check predictions based on predictor values\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply Scale value to outputs\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE using predictions and targets\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nLinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store linear regressor value\n",
        "rmse_LR = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate mean value of Number of Collisions\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Number of Collision Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2));\n",
        "print('Just using an average = {0}, has RMSE of {1}'.format(avg, rmse)); \n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "if(rmse_LR < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your Linear Regression model performs better than finding average!');\n",
        "else: \n",
        "  print('\\nSorry! On this run, your model performs worse than just finding the average!');\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1aa5c6898>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dew_visib_precip', '_session_creation_timeout_secs': 7200}\n",
            "starting to train...\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_dew_visib_precip/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.35254735, step = 1\n",
            "INFO:tensorflow:global_step/sec: 843.471\n",
            "INFO:tensorflow:loss = 99.94984, step = 101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.97\n",
            "INFO:tensorflow:loss = 5.6299715, step = 201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1043.44\n",
            "INFO:tensorflow:loss = 310.81183, step = 301 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.61\n",
            "INFO:tensorflow:loss = 3.5208807, step = 401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1064.45\n",
            "INFO:tensorflow:loss = 0.026513588, step = 501 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.915\n",
            "INFO:tensorflow:loss = 0.023035776, step = 601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.95\n",
            "INFO:tensorflow:loss = 0.023116533, step = 701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.932\n",
            "INFO:tensorflow:loss = 0.016466487, step = 801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.764\n",
            "INFO:tensorflow:loss = 0.03707807, step = 901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.257\n",
            "INFO:tensorflow:loss = 1.370096, step = 1001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1029.35\n",
            "INFO:tensorflow:loss = 625.0639, step = 1101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.612\n",
            "INFO:tensorflow:loss = 292.93118, step = 1201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.839\n",
            "INFO:tensorflow:loss = 2.0431244, step = 1301 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.338\n",
            "INFO:tensorflow:loss = 0.021006156, step = 1401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.94\n",
            "INFO:tensorflow:loss = 0.07010227, step = 1501 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.2\n",
            "INFO:tensorflow:loss = 0.019948501, step = 1601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.86\n",
            "INFO:tensorflow:loss = 0.025057023, step = 1701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.059\n",
            "INFO:tensorflow:loss = 0.024155077, step = 1801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.617\n",
            "INFO:tensorflow:loss = 0.088772565, step = 1901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.721\n",
            "INFO:tensorflow:loss = 0.69949996, step = 2001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.4\n",
            "INFO:tensorflow:loss = 214.53528, step = 2101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.395\n",
            "INFO:tensorflow:loss = 12.882959, step = 2201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.813\n",
            "INFO:tensorflow:loss = 3.5127122, step = 2301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.346\n",
            "INFO:tensorflow:loss = 0.36287853, step = 2401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.64\n",
            "INFO:tensorflow:loss = 0.044898327, step = 2501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.111\n",
            "INFO:tensorflow:loss = 0.26259786, step = 2601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.385\n",
            "INFO:tensorflow:loss = 1.6332569, step = 2701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.701\n",
            "INFO:tensorflow:loss = 3.4385424, step = 2801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.86\n",
            "INFO:tensorflow:loss = 28.079956, step = 2901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.936\n",
            "INFO:tensorflow:loss = 20.372879, step = 3001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.26\n",
            "INFO:tensorflow:loss = 17844.207, step = 3101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.714\n",
            "INFO:tensorflow:loss = 19.159927, step = 3201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.56\n",
            "INFO:tensorflow:loss = 1.5763534, step = 3301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.993\n",
            "INFO:tensorflow:loss = 3.0218275, step = 3401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.23\n",
            "INFO:tensorflow:loss = 13.745543, step = 3501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.069\n",
            "INFO:tensorflow:loss = 24.231861, step = 3601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1036.6\n",
            "INFO:tensorflow:loss = 69640.79, step = 3701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.543\n",
            "INFO:tensorflow:loss = 271.6079, step = 3801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.06\n",
            "INFO:tensorflow:loss = 99.12529, step = 3901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.557\n",
            "INFO:tensorflow:loss = 9.487256, step = 4001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.7\n",
            "INFO:tensorflow:loss = 11.553252, step = 4101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1005.5\n",
            "INFO:tensorflow:loss = 23.937122, step = 4201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.764\n",
            "INFO:tensorflow:loss = 21.201405, step = 4301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.363\n",
            "INFO:tensorflow:loss = 87.628815, step = 4401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.543\n",
            "INFO:tensorflow:loss = 1.8732071, step = 4501 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.87\n",
            "INFO:tensorflow:loss = 19.309454, step = 4601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.246\n",
            "INFO:tensorflow:loss = 4.113841, step = 4701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.573\n",
            "INFO:tensorflow:loss = 0.16276777, step = 4801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.63\n",
            "INFO:tensorflow:loss = 0.062858835, step = 4901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1025.04\n",
            "INFO:tensorflow:loss = 0.26682526, step = 5001 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.02\n",
            "INFO:tensorflow:loss = 0.03638279, step = 5101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.12\n",
            "INFO:tensorflow:loss = 0.030774577, step = 5201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.39\n",
            "INFO:tensorflow:loss = 3.092279, step = 5301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.775\n",
            "INFO:tensorflow:loss = 13.18579, step = 5401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.884\n",
            "INFO:tensorflow:loss = 16.394384, step = 5501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.236\n",
            "INFO:tensorflow:loss = 110.67645, step = 5601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.873\n",
            "INFO:tensorflow:loss = 46.27004, step = 5701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.22\n",
            "INFO:tensorflow:loss = 0.3722093, step = 5801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1035.04\n",
            "INFO:tensorflow:loss = 0.030471895, step = 5901 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1054.47\n",
            "INFO:tensorflow:loss = 0.03190444, step = 6001 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.19\n",
            "INFO:tensorflow:loss = 0.026685696, step = 6101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.782\n",
            "INFO:tensorflow:loss = 0.02944614, step = 6201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.152\n",
            "INFO:tensorflow:loss = 0.035794027, step = 6301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.101\n",
            "INFO:tensorflow:loss = 0.032645546, step = 6401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.12\n",
            "INFO:tensorflow:loss = 0.029169481, step = 6501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.189\n",
            "INFO:tensorflow:loss = 0.053939287, step = 6601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1051.82\n",
            "INFO:tensorflow:loss = 0.6535822, step = 6701 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.492\n",
            "INFO:tensorflow:loss = 5775.788, step = 6801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.907\n",
            "INFO:tensorflow:loss = 218.74384, step = 6901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.615\n",
            "INFO:tensorflow:loss = 334.9617, step = 7001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.925\n",
            "INFO:tensorflow:loss = 0.026292048, step = 7101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 956.857\n",
            "INFO:tensorflow:loss = 0.027739132, step = 7201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.73\n",
            "INFO:tensorflow:loss = 0.017666608, step = 7301 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.503\n",
            "INFO:tensorflow:loss = 0.021967366, step = 7401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.08\n",
            "INFO:tensorflow:loss = 0.023273699, step = 7501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1028.32\n",
            "INFO:tensorflow:loss = 0.027602725, step = 7601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1031.71\n",
            "INFO:tensorflow:loss = 0.02224038, step = 7701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.066\n",
            "INFO:tensorflow:loss = 0.016926628, step = 7801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.107\n",
            "INFO:tensorflow:loss = 0.019317433, step = 7901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1040.69\n",
            "INFO:tensorflow:loss = 0.054637697, step = 8001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.79\n",
            "INFO:tensorflow:loss = 1.543794, step = 8101 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.311\n",
            "INFO:tensorflow:loss = 39.39437, step = 8201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1021.37\n",
            "INFO:tensorflow:loss = 169.41219, step = 8301 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.37\n",
            "INFO:tensorflow:loss = 2.641823, step = 8401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 997.07\n",
            "INFO:tensorflow:loss = 0.030152356, step = 8501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.965\n",
            "INFO:tensorflow:loss = 0.02421628, step = 8601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.701\n",
            "INFO:tensorflow:loss = 0.027048282, step = 8701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.977\n",
            "INFO:tensorflow:loss = 0.025393225, step = 8801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.41\n",
            "INFO:tensorflow:loss = 0.026674755, step = 8901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.9\n",
            "INFO:tensorflow:loss = 0.029092379, step = 9001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.41\n",
            "INFO:tensorflow:loss = 0.023684453, step = 9101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.218\n",
            "INFO:tensorflow:loss = 0.02884531, step = 9201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.544\n",
            "INFO:tensorflow:loss = 0.026591573, step = 9301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 816.758\n",
            "INFO:tensorflow:loss = 0.027733907, step = 9401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.71\n",
            "INFO:tensorflow:loss = 0.03279638, step = 9501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1045.85\n",
            "INFO:tensorflow:loss = 0.01954664, step = 9601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.508\n",
            "INFO:tensorflow:loss = 0.028505675, step = 9701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.3\n",
            "INFO:tensorflow:loss = 0.021520058, step = 9801 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.33\n",
            "INFO:tensorflow:loss = 0.49936065, step = 9901 (0.098 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_dew_visib_precip/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.6849377.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dew_visib_precip/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "LinearRegression has RMSE of 2358.6310795594227\n",
            "Just using an average = 564.0223035952064, has RMSE of 135.04248912864233\n",
            "\n",
            "Sorry! On this run, your model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFN5a9NnhE_a"
      },
      "source": [
        "On several shuffled runs of this data, the linear regression model performed very badly, and far worse than simply calculating an average number for the number of collisions.  This model produces very strange results that can vary greatly and may not be useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjoLbG-XQPxa"
      },
      "source": [
        "**4.1.1 Linear Regression Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeaXSt4EQPxa"
      },
      "source": [
        "Perform linear regression validation test using values from the original data set reserved for testing.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5ff3kyEQPxb"
      },
      "source": [
        "\n",
        "# Perform linear regression validation test using values from the original data set reserved for testing.\n",
        "                                                                                                 \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dew_visib_precip', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVS0tm2YhYaL"
      },
      "source": [
        "The DNN performed better than linear regression and produced quite reasonable values.  Again, DNN under and over estimated both the extremes of outlier low and high target values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9MqREHAQPxb"
      },
      "source": [
        "# **4.2 Deep Neural Network Regressor**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dMa5AFHQPxb",
        "outputId": "aa1162b4-e3dc-4427-f7b0-13b0ec6e1982"
      },
      "source": [
        "# Import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Required for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# Remove any previously saved training model training\n",
        "shutil.rmtree('/tmp/DNN_collision_regression_trained_model_dew_visib_precipd', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_dew_visib_precip', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Print message to display start of training log\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model by passing predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE value to determine how well the model works using prediction and target values.\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nDNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store DNN regressoion value\n",
        "rmse_DNN = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate the mean of the Number of Collision Values.\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'])\n",
        "\n",
        "# Calculate RMSE using COLLISION Values and the mean of all target values to determine\n",
        "# if the DNN model is better than calculating the mean value.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Output success or failure message for this model\n",
        "if(rmse_DNN < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your DNN Regression model performs better than finding the average!'); # Success\n",
        "else: \n",
        "  print('\\nSorry! But on this run, your DNN Regression model performs worse than just finding the average!'); # Failure\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1aa4535c0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_dew_visib_precip', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_dew_visib_precip/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_collision_regression_trained_model_dew_visib_precip/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.018233953, step = 10001\n",
            "INFO:tensorflow:global_step/sec: 501.074\n",
            "INFO:tensorflow:loss = 0.013363397, step = 10101 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.285\n",
            "INFO:tensorflow:loss = 0.019213691, step = 10201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.27\n",
            "INFO:tensorflow:loss = 0.014923493, step = 10301 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.663\n",
            "INFO:tensorflow:loss = 0.021761581, step = 10401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.957\n",
            "INFO:tensorflow:loss = 0.019876756, step = 10501 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.183\n",
            "INFO:tensorflow:loss = 0.017203964, step = 10601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.414\n",
            "INFO:tensorflow:loss = 0.018687762, step = 10701 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.02\n",
            "INFO:tensorflow:loss = 0.016082373, step = 10801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.39\n",
            "INFO:tensorflow:loss = 0.014310377, step = 10901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.786\n",
            "INFO:tensorflow:loss = 0.024653971, step = 11001 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 704.074\n",
            "INFO:tensorflow:loss = 0.017166924, step = 11101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.364\n",
            "INFO:tensorflow:loss = 0.024580983, step = 11201 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.849\n",
            "INFO:tensorflow:loss = 0.018083703, step = 11301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.66\n",
            "INFO:tensorflow:loss = 0.018707179, step = 11401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.373\n",
            "INFO:tensorflow:loss = 0.022066958, step = 11501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.029\n",
            "INFO:tensorflow:loss = 0.016850438, step = 11601 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.462\n",
            "INFO:tensorflow:loss = 0.02513282, step = 11701 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.679\n",
            "INFO:tensorflow:loss = 0.0134996995, step = 11801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.311\n",
            "INFO:tensorflow:loss = 0.017163299, step = 11901 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.927\n",
            "INFO:tensorflow:loss = 0.018900491, step = 12001 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.832\n",
            "INFO:tensorflow:loss = 0.017303238, step = 12101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.155\n",
            "INFO:tensorflow:loss = 0.015383693, step = 12201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.609\n",
            "INFO:tensorflow:loss = 0.018461432, step = 12301 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.021\n",
            "INFO:tensorflow:loss = 0.018052656, step = 12401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.589\n",
            "INFO:tensorflow:loss = 0.017077446, step = 12501 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.024\n",
            "INFO:tensorflow:loss = 0.01556013, step = 12601 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.706\n",
            "INFO:tensorflow:loss = 0.016934877, step = 12701 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.864\n",
            "INFO:tensorflow:loss = 0.018510412, step = 12801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.293\n",
            "INFO:tensorflow:loss = 0.015007601, step = 12901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.494\n",
            "INFO:tensorflow:loss = 0.02105724, step = 13001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.396\n",
            "INFO:tensorflow:loss = 0.019724928, step = 13101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.634\n",
            "INFO:tensorflow:loss = 0.019762747, step = 13201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.132\n",
            "INFO:tensorflow:loss = 0.01796186, step = 13301 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.945\n",
            "INFO:tensorflow:loss = 0.02255016, step = 13401 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.061\n",
            "INFO:tensorflow:loss = 0.02311755, step = 13501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.175\n",
            "INFO:tensorflow:loss = 0.018501248, step = 13601 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.59\n",
            "INFO:tensorflow:loss = 0.018136779, step = 13701 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.183\n",
            "INFO:tensorflow:loss = 0.019579725, step = 13801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.109\n",
            "INFO:tensorflow:loss = 0.01903044, step = 13901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.008\n",
            "INFO:tensorflow:loss = 0.017487817, step = 14001 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.924\n",
            "INFO:tensorflow:loss = 0.014427211, step = 14101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.585\n",
            "INFO:tensorflow:loss = 0.023652453, step = 14201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.643\n",
            "INFO:tensorflow:loss = 0.019612614, step = 14301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.053\n",
            "INFO:tensorflow:loss = 0.01903737, step = 14401 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.223\n",
            "INFO:tensorflow:loss = 0.01786406, step = 14501 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.845\n",
            "INFO:tensorflow:loss = 0.020211175, step = 14601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.901\n",
            "INFO:tensorflow:loss = 0.020129882, step = 14701 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.817\n",
            "INFO:tensorflow:loss = 0.016959481, step = 14801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.557\n",
            "INFO:tensorflow:loss = 0.018741863, step = 14901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.663\n",
            "INFO:tensorflow:loss = 0.02153318, step = 15001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.798\n",
            "INFO:tensorflow:loss = 0.014238146, step = 15101 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.237\n",
            "INFO:tensorflow:loss = 0.019572275, step = 15201 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.617\n",
            "INFO:tensorflow:loss = 0.0228263, step = 15301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.015\n",
            "INFO:tensorflow:loss = 0.019649059, step = 15401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.359\n",
            "INFO:tensorflow:loss = 0.020160131, step = 15501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.001\n",
            "INFO:tensorflow:loss = 0.016351977, step = 15601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.9\n",
            "INFO:tensorflow:loss = 0.01811592, step = 15701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.561\n",
            "INFO:tensorflow:loss = 0.014929873, step = 15801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.445\n",
            "INFO:tensorflow:loss = 0.017770795, step = 15901 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.785\n",
            "INFO:tensorflow:loss = 0.01965766, step = 16001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.25\n",
            "INFO:tensorflow:loss = 0.020047901, step = 16101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.628\n",
            "INFO:tensorflow:loss = 0.020972136, step = 16201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.542\n",
            "INFO:tensorflow:loss = 0.017795779, step = 16301 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.798\n",
            "INFO:tensorflow:loss = 0.022669788, step = 16401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.728\n",
            "INFO:tensorflow:loss = 0.018889036, step = 16501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.296\n",
            "INFO:tensorflow:loss = 0.017095812, step = 16601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.952\n",
            "INFO:tensorflow:loss = 0.015024329, step = 16701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.42\n",
            "INFO:tensorflow:loss = 0.016645528, step = 16801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.568\n",
            "INFO:tensorflow:loss = 0.020498056, step = 16901 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.433\n",
            "INFO:tensorflow:loss = 0.022510044, step = 17001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.225\n",
            "INFO:tensorflow:loss = 0.020921491, step = 17101 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.563\n",
            "INFO:tensorflow:loss = 0.026666988, step = 17201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.422\n",
            "INFO:tensorflow:loss = 0.014377514, step = 17301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.008\n",
            "INFO:tensorflow:loss = 0.019713236, step = 17401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.543\n",
            "INFO:tensorflow:loss = 0.019099802, step = 17501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.059\n",
            "INFO:tensorflow:loss = 0.023722328, step = 17601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.426\n",
            "INFO:tensorflow:loss = 0.021883864, step = 17701 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.747\n",
            "INFO:tensorflow:loss = 0.016715474, step = 17801 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.914\n",
            "INFO:tensorflow:loss = 0.019015707, step = 17901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.63\n",
            "INFO:tensorflow:loss = 0.02077171, step = 18001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.441\n",
            "INFO:tensorflow:loss = 0.015979268, step = 18101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.569\n",
            "INFO:tensorflow:loss = 0.017329568, step = 18201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.618\n",
            "INFO:tensorflow:loss = 0.019304883, step = 18301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.248\n",
            "INFO:tensorflow:loss = 0.018309575, step = 18401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.327\n",
            "INFO:tensorflow:loss = 0.015112841, step = 18501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.225\n",
            "INFO:tensorflow:loss = 0.015216211, step = 18601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.072\n",
            "INFO:tensorflow:loss = 0.015185809, step = 18701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.483\n",
            "INFO:tensorflow:loss = 0.019721713, step = 18801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.041\n",
            "INFO:tensorflow:loss = 0.017146494, step = 18901 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.923\n",
            "INFO:tensorflow:loss = 0.018351447, step = 19001 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.758\n",
            "INFO:tensorflow:loss = 0.021815332, step = 19101 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.095\n",
            "INFO:tensorflow:loss = 0.022506949, step = 19201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.582\n",
            "INFO:tensorflow:loss = 0.019835811, step = 19301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.719\n",
            "INFO:tensorflow:loss = 0.021103099, step = 19401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.712\n",
            "INFO:tensorflow:loss = 0.025158003, step = 19501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.066\n",
            "INFO:tensorflow:loss = 0.014289763, step = 19601 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.858\n",
            "INFO:tensorflow:loss = 0.01613847, step = 19701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.245\n",
            "INFO:tensorflow:loss = 0.018695723, step = 19801 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.348\n",
            "INFO:tensorflow:loss = 0.01399696, step = 19901 (0.170 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/DNN_collision_regression_trained_model_dew_visib_precip/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.021788424.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_dew_visib_precip/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "DNNRegression has RMSE of 134.97312252493697\n",
            "Just using average = 564.0223035952064 has RMSE of 135.04248912864233\n",
            "\n",
            "Great! Your DNN Regression model performs better than finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BksknKlQPxc"
      },
      "source": [
        "**4.2.1 Deep Neural Network Validation Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JncpMbcQPxc",
        "outputId": "e7bfd091-a468-4fbe-8796-e8c185d0c707"
      },
      "source": [
        "# Perform validation assessment of DNN model using test values reserved from original dataset\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_dew_visib_precip', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "# Use test values reserved from original data set\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1aa6c3400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_dew_visib_precip', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_dew_visib_precip/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662 563.0662\n",
            " 563.0662 563.0662]\n",
            "\n",
            "==== Target Collision Values ==== [732 734 510 626 562 649 747 648 662 198 629 600 389 607 598 474 628 546\n",
            " 552 614 482 617 625 538 649 597 606 190 597 565 362 528 757 476 960 173\n",
            " 595 719 264 697 670 703 534 629 696 665 757 675 643 672]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAR1EuFcQPxc"
      },
      "source": [
        "From the results of the DNN validation test, it can be seen that many of the predicted values seem to be very strange and in most runs the results are mainly identical values.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSDM9LNDQPxc"
      },
      "source": [
        "# **4.3 Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkYg2jKMQPxc"
      },
      "source": [
        "From the results of the linear and DNN models, we can see that the linear model performed worse than just finding the average number of collisions using a mean value, and the DNN model produced some strange results.  This is not a good model to use.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3IbzKsBR22h"
      },
      "source": [
        "#**5. Month, Day, Mean Temperature, Max and Min Temp, Precipitation**\r\n",
        "\r\n",
        "I will attempt to combine factors from the better performing models, to determine if improvements can be seen in the model performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhaPX0n4R22n"
      },
      "source": [
        "# Import pandas to allow creation of data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Create data frame from github csv file\n",
        "source_dataframe = pd.read_csv('https://raw.githubusercontent.com/15014370uhi/15014370_DataAnalytics/master/bq-cleansed_weather_reduced_assignment_1.csv', index_col=0,);"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7jKZ75R22n",
        "outputId": "ca12920f-a5f4-40d7-c477-451e5fbaae75"
      },
      "source": [
        "# Check that correct data is present\n",
        "print(source_dataframe) "
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  da  day  temp  dewp  ...  mxpsd   max   min  prcp  NUM_COLLISIONS\n",
            "year                           ...                                         \n",
            "2012   7   1    7  83.6  63.0  ...    9.9  93.0  66.0  0.00             538\n",
            "2012   7   2    1  80.3  54.1  ...   15.0  88.0  66.9  0.00             564\n",
            "2012   7   3    2  79.8  56.7  ...   12.0  88.0  63.0  0.00             664\n",
            "2012   7   4    3  81.8  65.6  ...   11.1  91.0  68.0  0.06             432\n",
            "2012   7   6    5  81.9  62.3  ...    9.9  91.0  66.9  0.00             638\n",
            "...   ..  ..  ...   ...   ...  ...    ...   ...   ...   ...             ...\n",
            "2020  12   1    2  58.1  54.3  ...   34.0  63.0  45.0  0.88             253\n",
            "2020  12   2    3  47.5  35.9  ...   22.9  63.0  42.1  0.59             204\n",
            "2020  12   3    4  45.1  32.4  ...   18.1  52.0  36.0  0.02             218\n",
            "2020  12   4    5  53.6  43.8  ...   18.1  59.0  36.0  0.00             319\n",
            "2020  12   5    6  51.9  48.9  ...   32.1  59.0  39.9  0.32             222\n",
            "\n",
            "[3054 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LurDnt9ER22n",
        "outputId": "1311c3c6-b648-473e-d901-ab3f9831aa46"
      },
      "source": [
        "# Find the total length of data rows\r\n",
        "totalNumberOfRows = len(source_dataframe);\r\n",
        "print(totalNumberOfRows);"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92SOtp3IR22o"
      },
      "source": [
        "# Import numpty to improve speed of math calculations\n",
        "import numpy as np"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Txbev3LR22o"
      },
      "source": [
        "# Shuffle all source data\r\n",
        "source_dataframe = source_dataframe.iloc[np.random.permutation(len(source_dataframe))]; "
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yldw12xvR22o"
      },
      "source": [
        "# Number of rows to reserve for testing\r\n",
        "number_of_test_rows = 50"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM7OBFRsR22o"
      },
      "source": [
        "# Store training data as (all rows - number_of_test_rows) of source data\n",
        "df_train = source_dataframe[:-number_of_test_rows];\n",
        "\n",
        "# Shuffle training data a second time\n",
        "df_train = df_train.iloc[np.random.permutation(len(df_train))]; \n",
        "\n",
        "# Store validation test data as last number_of_test_rows of rows of source data\n",
        "df_test = source_dataframe[-number_of_test_rows:];\n",
        "\n",
        "# Shuffle test data a second time\n",
        "df_test = df_test.iloc[np.random.permutation(len(df_test))];\n",
        "\n",
        "# Store only relevant columns of data for this model\n",
        "df_train = df_train.iloc[:, [0,2,3,9,10,11,12]]; \n",
        "df_test = df_test.iloc[:, [0,2,3,9,10,11,12]];\n"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l5Z0kvwR22o",
        "outputId": "14e74727-21cf-489b-c812-a88532ef9d83"
      },
      "source": [
        "# Confirm training data is stored \r\n",
        "print(df_train)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  day  temp   max   min  prcp  NUM_COLLISIONS\n",
            "year                                                 \n",
            "2019   1    3  44.4  46.9  28.9  0.12             514\n",
            "2019   8    7  71.2  79.0  62.1  0.00             481\n",
            "2016   8    5  74.4  81.0  64.9  0.00             707\n",
            "2018   4    1  46.2  57.9  41.0  0.07             656\n",
            "2015  10    6  52.7  66.0  41.0  0.07             565\n",
            "...   ..  ...   ...   ...   ...   ...             ...\n",
            "2016   2    7   5.8  27.0  -2.0  0.00             309\n",
            "2020   5    4  48.3  57.0  36.0  0.00             211\n",
            "2018   6    5  54.8  62.1  43.0  0.00             757\n",
            "2015  11    5  58.3  61.0  51.1  0.07             677\n",
            "2018   5    1  53.0  63.0  46.0  0.48             695\n",
            "\n",
            "[3004 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlGAD0dbR22o",
        "outputId": "0f2bb403-68e7-492a-8908-1b5339eb6b0d"
      },
      "source": [
        "# Confirm test data rows are stored\r\n",
        "print(df_test);"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  day  temp   max   min  prcp  NUM_COLLISIONS\n",
            "year                                                 \n",
            "2013   6    2  61.8  66.0  57.2  0.34             613\n",
            "2018  10    3  48.8  59.0  44.1  0.03             719\n",
            "2017   7    3  63.6  72.0  55.0  0.00             635\n",
            "2019  11    4  35.0  48.0  21.9  0.00             545\n",
            "2019  12    2  44.7  52.0  37.9  0.88             443\n",
            "2015   6    6  68.0  79.0  61.0  0.02             395\n",
            "2016   2    6  23.5  27.0  12.9  0.00             480\n",
            "2018   6    1  56.2  68.0  51.1  0.00             686\n",
            "2016   1    6  45.7  51.1  39.9  1.30             563\n",
            "2012  11    3  37.1  48.2  30.9  0.00             718\n",
            "2018   9    7  63.9  75.9  54.0  0.00             597\n",
            "2015   8    7  67.0  77.0  64.0  0.00             489\n",
            "2017   8    5  67.7  75.9  61.0  0.00             758\n",
            "2018   4    5  47.7  51.1  37.0  0.02             755\n",
            "2015  11    3  39.6  50.0  28.9  0.00             717\n",
            "2020   4    2  41.8  50.0  39.0  0.13             185\n",
            "2018  12    1  32.0  43.0  21.0  0.00             622\n",
            "2016  11    6  47.8  55.9  36.0  0.00             626\n",
            "2019   3    5  42.3  48.0  36.0  0.75             718\n",
            "2020   1    4  29.5  42.1  24.1  0.34             517\n",
            "2015  12    3  46.5  61.0  43.0  0.35             673\n",
            "2019   3    6  39.3  46.0  32.0  0.00             530\n",
            "2015   5    5  43.8  57.0  39.0  0.00             642\n",
            "2015   3    3  36.1  41.0  23.0  0.31             574\n",
            "2018   7    6  59.8  73.0  52.0  0.00             622\n",
            "2012  10    4  58.0  61.0  43.0  0.00             511\n",
            "2018   6    2  55.3  64.0  46.0  0.00             720\n",
            "2019   1    3  35.0  55.0  28.0  0.61             502\n",
            "2016   4    7  49.1  60.1  44.1  0.26             448\n",
            "2013   2    4  41.4  46.9  39.0  0.32             517\n",
            "2014  10    1  54.1  61.0  48.9  0.00             642\n",
            "2020   4    3  39.9  44.1  34.0  0.00             154\n",
            "2018   1    5  23.0  42.1  15.1  2.14             700\n",
            "2018  12    3  29.8  39.0  21.0  0.00             749\n",
            "2012   9    5  65.2  69.1  51.8  0.25             703\n",
            "2019   7    2  73.0  80.1  69.1  0.00             638\n",
            "2013   8    3  70.3  79.0  64.0  0.00             562\n",
            "2017   2    3  36.6  44.1  21.9  0.00             603\n",
            "2014   5    5  49.7  57.9  41.0  0.00             650\n",
            "2014  10    1  49.0  59.0  41.0  0.00             591\n",
            "2015   7    3  73.7  82.0  68.0  0.00             618\n",
            "2015   2    4  27.0  36.0  19.9  0.00             515\n",
            "2015   5    7  64.7  71.1  59.0  0.00             555\n",
            "2014   7    2  68.6  73.9  54.0  0.01             616\n",
            "2014   4    5  40.4  46.0  35.1  0.00             496\n",
            "2019   9    2  61.5  70.0  54.0  0.00             635\n",
            "2020   1    2  41.5  44.1  37.9  0.00             497\n",
            "2018   7    7  72.9  80.1  66.9  0.06             463\n",
            "2019   8    5  66.6  73.9  62.1  0.00             523\n",
            "2012  10    6  45.2  52.0  37.9  0.00             547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8NBMvWR22p"
      },
      "source": [
        "# Select Predictor columns for training and testing data to be used to predict the outcome\n",
        "\n",
        "predictors_train = df_train.iloc[:, [0,1,2,3,4,5]];\n",
        "predictors_test = df_test.iloc[:,  [0,1,2,3,4,5]];"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VJ8T4iVR22p",
        "outputId": "d1947e85-9fe7-4f9d-9a87-d7f35482421d"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_train)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  day  temp   max   min  prcp\n",
            "year                                 \n",
            "2019   1    3  44.4  46.9  28.9  0.12\n",
            "2019   8    7  71.2  79.0  62.1  0.00\n",
            "2016   8    5  74.4  81.0  64.9  0.00\n",
            "2018   4    1  46.2  57.9  41.0  0.07\n",
            "2015  10    6  52.7  66.0  41.0  0.07\n",
            "...   ..  ...   ...   ...   ...   ...\n",
            "2016   2    7   5.8  27.0  -2.0  0.00\n",
            "2020   5    4  48.3  57.0  36.0  0.00\n",
            "2018   6    5  54.8  62.1  43.0  0.00\n",
            "2015  11    5  58.3  61.0  51.1  0.07\n",
            "2018   5    1  53.0  63.0  46.0  0.48\n",
            "\n",
            "[3004 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0yphcY_R22p",
        "outputId": "9a4be7c8-05cc-4b3c-dafd-2a0e5311e706"
      },
      "source": [
        "# confirm predictor holds correct data\r\n",
        "print(predictors_test);"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      mo  day  temp   max   min  prcp\n",
            "year                                 \n",
            "2013   6    2  61.8  66.0  57.2  0.34\n",
            "2018  10    3  48.8  59.0  44.1  0.03\n",
            "2017   7    3  63.6  72.0  55.0  0.00\n",
            "2019  11    4  35.0  48.0  21.9  0.00\n",
            "2019  12    2  44.7  52.0  37.9  0.88\n",
            "2015   6    6  68.0  79.0  61.0  0.02\n",
            "2016   2    6  23.5  27.0  12.9  0.00\n",
            "2018   6    1  56.2  68.0  51.1  0.00\n",
            "2016   1    6  45.7  51.1  39.9  1.30\n",
            "2012  11    3  37.1  48.2  30.9  0.00\n",
            "2018   9    7  63.9  75.9  54.0  0.00\n",
            "2015   8    7  67.0  77.0  64.0  0.00\n",
            "2017   8    5  67.7  75.9  61.0  0.00\n",
            "2018   4    5  47.7  51.1  37.0  0.02\n",
            "2015  11    3  39.6  50.0  28.9  0.00\n",
            "2020   4    2  41.8  50.0  39.0  0.13\n",
            "2018  12    1  32.0  43.0  21.0  0.00\n",
            "2016  11    6  47.8  55.9  36.0  0.00\n",
            "2019   3    5  42.3  48.0  36.0  0.75\n",
            "2020   1    4  29.5  42.1  24.1  0.34\n",
            "2015  12    3  46.5  61.0  43.0  0.35\n",
            "2019   3    6  39.3  46.0  32.0  0.00\n",
            "2015   5    5  43.8  57.0  39.0  0.00\n",
            "2015   3    3  36.1  41.0  23.0  0.31\n",
            "2018   7    6  59.8  73.0  52.0  0.00\n",
            "2012  10    4  58.0  61.0  43.0  0.00\n",
            "2018   6    2  55.3  64.0  46.0  0.00\n",
            "2019   1    3  35.0  55.0  28.0  0.61\n",
            "2016   4    7  49.1  60.1  44.1  0.26\n",
            "2013   2    4  41.4  46.9  39.0  0.32\n",
            "2014  10    1  54.1  61.0  48.9  0.00\n",
            "2020   4    3  39.9  44.1  34.0  0.00\n",
            "2018   1    5  23.0  42.1  15.1  2.14\n",
            "2018  12    3  29.8  39.0  21.0  0.00\n",
            "2012   9    5  65.2  69.1  51.8  0.25\n",
            "2019   7    2  73.0  80.1  69.1  0.00\n",
            "2013   8    3  70.3  79.0  64.0  0.00\n",
            "2017   2    3  36.6  44.1  21.9  0.00\n",
            "2014   5    5  49.7  57.9  41.0  0.00\n",
            "2014  10    1  49.0  59.0  41.0  0.00\n",
            "2015   7    3  73.7  82.0  68.0  0.00\n",
            "2015   2    4  27.0  36.0  19.9  0.00\n",
            "2015   5    7  64.7  71.1  59.0  0.00\n",
            "2014   7    2  68.6  73.9  54.0  0.01\n",
            "2014   4    5  40.4  46.0  35.1  0.00\n",
            "2019   9    2  61.5  70.0  54.0  0.00\n",
            "2020   1    2  41.5  44.1  37.9  0.00\n",
            "2018   7    7  72.9  80.1  66.9  0.06\n",
            "2019   8    5  66.6  73.9  62.1  0.00\n",
            "2012  10    6  45.2  52.0  37.9  0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykb3qXoyR22p"
      },
      "source": [
        "# Select target columns\n",
        "targets_train = df_train.iloc[:,6];\n",
        "\n",
        "# Select target columns\n",
        "targets_test = df_test.iloc[:,6];"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJycUFymR22p",
        "outputId": "1bb1a6af-1e91-4d43-bf9c-0b52dbdf7ae2"
      },
      "source": [
        "print(targets_train);"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2019    514\n",
            "2019    481\n",
            "2016    707\n",
            "2018    656\n",
            "2015    565\n",
            "       ... \n",
            "2016    309\n",
            "2020    211\n",
            "2018    757\n",
            "2015    677\n",
            "2018    695\n",
            "Name: NUM_COLLISIONS, Length: 3004, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73r4BYEIR22p",
        "outputId": "581586c8-5bf7-4fee-924e-f5c6b5f5b619"
      },
      "source": [
        "print(targets_test);"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "year\n",
            "2013    613\n",
            "2018    719\n",
            "2017    635\n",
            "2019    545\n",
            "2019    443\n",
            "2015    395\n",
            "2016    480\n",
            "2018    686\n",
            "2016    563\n",
            "2012    718\n",
            "2018    597\n",
            "2015    489\n",
            "2017    758\n",
            "2018    755\n",
            "2015    717\n",
            "2020    185\n",
            "2018    622\n",
            "2016    626\n",
            "2019    718\n",
            "2020    517\n",
            "2015    673\n",
            "2019    530\n",
            "2015    642\n",
            "2015    574\n",
            "2018    622\n",
            "2012    511\n",
            "2018    720\n",
            "2019    502\n",
            "2016    448\n",
            "2013    517\n",
            "2014    642\n",
            "2020    154\n",
            "2018    700\n",
            "2018    749\n",
            "2012    703\n",
            "2019    638\n",
            "2013    562\n",
            "2017    603\n",
            "2014    650\n",
            "2014    591\n",
            "2015    618\n",
            "2015    515\n",
            "2015    555\n",
            "2014    616\n",
            "2014    496\n",
            "2019    635\n",
            "2020    497\n",
            "2018    463\n",
            "2019    523\n",
            "2012    547\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Hz9yqJR22q"
      },
      "source": [
        "# Set scale value\n",
        "SCALE_NUM_COLLISIONS = 1000.0;"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr3WO_0XR22q"
      },
      "source": [
        "# Get size of training set \n",
        "trainsize = int(len(df_train['NUM_COLLISIONS']));\n",
        "\n",
        "# Get size of test set \n",
        "testsize = int(len(df_test['NUM_COLLISIONS']));"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQtaIGg6R22q",
        "outputId": "7f7ea9ed-c037-4409-85b5-4bb7d08b66b2"
      },
      "source": [
        "print(trainsize);"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht1fv09UR22q",
        "outputId": "a445fe0d-03a0-41f7-b8da-26bdc16b81d8"
      },
      "source": [
        "print(testsize);"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwNmj6RfR22q"
      },
      "source": [
        "\r\n",
        "# Define the number of predictor column input values\r\n",
        "nppredictors = len(predictors_train.columns);\r\n",
        "\r\n",
        "# Define the number of target column output values\r\n",
        "noutputs = 1;\r\n"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIMw8F4hR22q",
        "outputId": "47d4c11a-3d06-463d-b127-00924d53a2c1"
      },
      "source": [
        "print(nppredictors)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1OQFJs7R22q"
      },
      "source": [
        "# **5.1 Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoRWQqG7R22q",
        "outputId": "9d1a6316-6172-4f65-bd91-89e3ab27728c"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_combined_day_temps_percp', ignore_errors=True)\n",
        "   \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_combined_day_temps_percp', optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Prints log to show start of training model\n",
        "print(\"starting to train...\\n\");\n",
        "\n",
        "# Train the model using predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Check predictions based on predictor values\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply Scale value to outputs\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE using predictions and targets\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nLinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store linear regressor value\n",
        "rmse_LR = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate mean value of Number of Collisions\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "# Calculate the RMSE using Number of Collision Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2));\n",
        "print('Just using an average = {0}, has RMSE of {1}'.format(avg, rmse)); \n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "if(rmse_LR < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your Linear Regression model performs better than finding average!');\n",
        "else: \n",
        "  print('\\nSorry! On this run, your model performs worse than just finding the average!');\n"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1af985da0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_combined_day_temps_percp', '_session_creation_timeout_secs': 7200}\n",
            "starting to train...\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_combined_day_temps_percp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.33739263, step = 1\n",
            "INFO:tensorflow:global_step/sec: 813.501\n",
            "INFO:tensorflow:loss = 0.029219026, step = 101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.466\n",
            "INFO:tensorflow:loss = 0.032917913, step = 201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.44\n",
            "INFO:tensorflow:loss = 0.018178102, step = 301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 937.65\n",
            "INFO:tensorflow:loss = 0.014896482, step = 401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1012.04\n",
            "INFO:tensorflow:loss = 0.020107778, step = 501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.919\n",
            "INFO:tensorflow:loss = 0.025967363, step = 601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.951\n",
            "INFO:tensorflow:loss = 0.01901508, step = 701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.123\n",
            "INFO:tensorflow:loss = 0.022113778, step = 801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.949\n",
            "INFO:tensorflow:loss = 0.020221025, step = 901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.966\n",
            "INFO:tensorflow:loss = 0.023551248, step = 1001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.359\n",
            "INFO:tensorflow:loss = 0.018985782, step = 1101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.678\n",
            "INFO:tensorflow:loss = 0.034313574, step = 1201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.51\n",
            "INFO:tensorflow:loss = 0.01635585, step = 1301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.838\n",
            "INFO:tensorflow:loss = 0.013585661, step = 1401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.055\n",
            "INFO:tensorflow:loss = 0.03773321, step = 1501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.048\n",
            "INFO:tensorflow:loss = 0.049792692, step = 1601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.12\n",
            "INFO:tensorflow:loss = 0.047701173, step = 1701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.563\n",
            "INFO:tensorflow:loss = 0.028972758, step = 1801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.148\n",
            "INFO:tensorflow:loss = 0.11073321, step = 1901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.98\n",
            "INFO:tensorflow:loss = 0.04894643, step = 2001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.984\n",
            "INFO:tensorflow:loss = 1.2389035, step = 2101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.767\n",
            "INFO:tensorflow:loss = 0.121549904, step = 2201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.12\n",
            "INFO:tensorflow:loss = 0.059675016, step = 2301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.744\n",
            "INFO:tensorflow:loss = 0.057553347, step = 2401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.317\n",
            "INFO:tensorflow:loss = 0.104383074, step = 2501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 895.727\n",
            "INFO:tensorflow:loss = 0.1569084, step = 2601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.49\n",
            "INFO:tensorflow:loss = 0.061665196, step = 2701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.982\n",
            "INFO:tensorflow:loss = 0.03711272, step = 2801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007.15\n",
            "INFO:tensorflow:loss = 0.08497611, step = 2901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.385\n",
            "INFO:tensorflow:loss = 0.016328316, step = 3001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.78\n",
            "INFO:tensorflow:loss = 0.09261977, step = 3101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.69\n",
            "INFO:tensorflow:loss = 0.25703615, step = 3201 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.804\n",
            "INFO:tensorflow:loss = 0.10494024, step = 3301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.388\n",
            "INFO:tensorflow:loss = 0.021889016, step = 3401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.19\n",
            "INFO:tensorflow:loss = 0.053988207, step = 3501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.379\n",
            "INFO:tensorflow:loss = 0.018817859, step = 3601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.733\n",
            "INFO:tensorflow:loss = 0.06450041, step = 3701 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.998\n",
            "INFO:tensorflow:loss = 0.11379632, step = 3801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.599\n",
            "INFO:tensorflow:loss = 0.43946567, step = 3901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.235\n",
            "INFO:tensorflow:loss = 1.3569956, step = 4001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.173\n",
            "INFO:tensorflow:loss = 0.016691303, step = 4101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.79\n",
            "INFO:tensorflow:loss = 0.04599265, step = 4201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.489\n",
            "INFO:tensorflow:loss = 0.17780867, step = 4301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.963\n",
            "INFO:tensorflow:loss = 0.024925066, step = 4401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.308\n",
            "INFO:tensorflow:loss = 3.0872858, step = 4501 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.256\n",
            "INFO:tensorflow:loss = 0.0137396455, step = 4601 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.85\n",
            "INFO:tensorflow:loss = 0.053130098, step = 4701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.815\n",
            "INFO:tensorflow:loss = 1.2358532, step = 4801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.443\n",
            "INFO:tensorflow:loss = 0.016127035, step = 4901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.332\n",
            "INFO:tensorflow:loss = 0.2628747, step = 5001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.178\n",
            "INFO:tensorflow:loss = 0.034878142, step = 5101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.707\n",
            "INFO:tensorflow:loss = 0.21811384, step = 5201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.377\n",
            "INFO:tensorflow:loss = 0.041850083, step = 5301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.922\n",
            "INFO:tensorflow:loss = 0.020453297, step = 5401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.223\n",
            "INFO:tensorflow:loss = 0.16568163, step = 5501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.31\n",
            "INFO:tensorflow:loss = 0.020663317, step = 5601 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.304\n",
            "INFO:tensorflow:loss = 0.0204497, step = 5701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 997.589\n",
            "INFO:tensorflow:loss = 0.20797586, step = 5801 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.23\n",
            "INFO:tensorflow:loss = 0.623679, step = 5901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.966\n",
            "INFO:tensorflow:loss = 0.013816437, step = 6001 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.945\n",
            "INFO:tensorflow:loss = 0.2683701, step = 6101 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.903\n",
            "INFO:tensorflow:loss = 0.7389451, step = 6201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.457\n",
            "INFO:tensorflow:loss = 0.16575065, step = 6301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.784\n",
            "INFO:tensorflow:loss = 0.38005868, step = 6401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.782\n",
            "INFO:tensorflow:loss = 0.13335481, step = 6501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.171\n",
            "INFO:tensorflow:loss = 2.6496162, step = 6601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.171\n",
            "INFO:tensorflow:loss = 0.04225424, step = 6701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.742\n",
            "INFO:tensorflow:loss = 0.019852772, step = 6801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.9\n",
            "INFO:tensorflow:loss = 0.02716514, step = 6901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.079\n",
            "INFO:tensorflow:loss = 0.2052721, step = 7001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.07\n",
            "INFO:tensorflow:loss = 0.3267684, step = 7101 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.883\n",
            "INFO:tensorflow:loss = 0.09477785, step = 7201 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.385\n",
            "INFO:tensorflow:loss = 0.036331777, step = 7301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.3\n",
            "INFO:tensorflow:loss = 0.3537107, step = 7401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1032.25\n",
            "INFO:tensorflow:loss = 0.02001793, step = 7501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.012\n",
            "INFO:tensorflow:loss = 0.03381586, step = 7601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1031.47\n",
            "INFO:tensorflow:loss = 0.5599123, step = 7701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.07\n",
            "INFO:tensorflow:loss = 0.37859827, step = 7801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.618\n",
            "INFO:tensorflow:loss = 0.033180147, step = 7901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.825\n",
            "INFO:tensorflow:loss = 0.034027465, step = 8001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.891\n",
            "INFO:tensorflow:loss = 0.023398535, step = 8101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.79\n",
            "INFO:tensorflow:loss = 0.0220927, step = 8201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.026\n",
            "INFO:tensorflow:loss = 0.055381216, step = 8301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.008\n",
            "INFO:tensorflow:loss = 0.029328002, step = 8401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.213\n",
            "INFO:tensorflow:loss = 0.036644522, step = 8501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.092\n",
            "INFO:tensorflow:loss = 0.02524415, step = 8601 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.825\n",
            "INFO:tensorflow:loss = 0.049596526, step = 8701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.2\n",
            "INFO:tensorflow:loss = 2.6557379, step = 8801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.069\n",
            "INFO:tensorflow:loss = 0.34526765, step = 8901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.655\n",
            "INFO:tensorflow:loss = 0.1598988, step = 9001 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.171\n",
            "INFO:tensorflow:loss = 0.34665382, step = 9101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.78\n",
            "INFO:tensorflow:loss = 0.01649278, step = 9201 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.44\n",
            "INFO:tensorflow:loss = 0.18554212, step = 9301 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.294\n",
            "INFO:tensorflow:loss = 0.24607386, step = 9401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.993\n",
            "INFO:tensorflow:loss = 0.09366517, step = 9501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.67\n",
            "INFO:tensorflow:loss = 0.023333464, step = 9601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.332\n",
            "INFO:tensorflow:loss = 0.19314313, step = 9701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.952\n",
            "INFO:tensorflow:loss = 0.042930126, step = 9801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.745\n",
            "INFO:tensorflow:loss = 0.024414781, step = 9901 (0.106 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_combined_day_temps_percp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.070338026.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_combined_day_temps_percp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "LinearRegression has RMSE of 165.82654594552486\n",
            "Just using an average = 564.1451398135819, has RMSE of 135.49527033063225\n",
            "\n",
            "Sorry! On this run, your model performs worse than just finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U48Ly7p7R22r"
      },
      "source": [
        "**5.1.1 Linear Regression Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1vPTvl1R22r"
      },
      "source": [
        "Perform linear regression validation test using values from the original data set reserved for testing.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Pz0yxwR22r",
        "outputId": "4097e356-742e-4a20-afb7-cd9c99086426"
      },
      "source": [
        "\n",
        "# Perform linear regression validation test using values from the original data set reserved for testing.\n",
        "                                                                                                 \n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_combined_day_temps_percp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1afaea4a8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_combined_day_temps_percp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_combined_day_temps_percp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "==== Predicted Number of Collisions ==== [703.8218  683.291   702.64294 644.93134 694.19574 668.502   538.94336\n",
            " 717.17694 592.8764  661.6627  657.24316 657.37726 685.7985  616.85876\n",
            " 666.19464 656.2026  683.36194 636.5799  606.53815 594.4067  693.58746\n",
            " 584.2088  627.63    619.44824 657.0351  677.6067  695.1511  634.62115\n",
            " 603.349   614.0208  719.7886  630.0707  580.292   645.6614  677.5793\n",
            " 737.0411  722.3519  620.04205 633.01025 713.07245 725.6686  585.6876\n",
            " 634.73676 723.9214  603.7076  720.5723  634.564   662.6638  681.85474\n",
            " 624.7486 ]\n",
            "\n",
            "==== Target Collision Values ==== [613 719 635 545 443 395 480 686 563 718 597 489 758 755 717 185 622 626\n",
            " 718 517 673 530 642 574 622 511 720 502 448 517 642 154 700 749 703 638\n",
            " 562 603 650 591 618 515 555 616 496 635 497 463 523 547]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6KeKe3lR22r"
      },
      "source": [
        "# **5.2 Deep Neural Network Regressor**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAPT2veHR22s",
        "outputId": "f940c297-cb59-4285-cdea-38dfd80ea0ac"
      },
      "source": [
        "# Import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Required for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) # Supress verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # Show verbosity\n",
        "\n",
        "# Remove any previously saved training model training\n",
        "shutil.rmtree('/tmp/DNN_collision_regression_trained_model_combined_day_temps_percp', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_combined_day_temps_percp', hidden_units=[20,18,14], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_train.values)))\n",
        "\n",
        "# Print message to display start of training log\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model by passing predictor and target values\n",
        "estimator.fit(predictors_train.values, targets_train.values.reshape(trainsize, noutputs)/SCALE_NUM_COLLISIONS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_train.values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "\n",
        "# Calculate RMSE value to determine how well the model works using prediction and target values.\n",
        "rmse = np.sqrt(np.mean((targets_train.values - predslistscale)**2))\n",
        "print('\\nDNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Store DNN regressoion value\n",
        "rmse_DNN = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Calculate the mean of the Number of Collision Values.\n",
        "avg = np.mean(df_train['NUM_COLLISIONS'])\n",
        "\n",
        "# Calculate RMSE using COLLISION Values and the mean of all target values to determine\n",
        "# if the DNN model is better than calculating the mean value.\n",
        "rmse = np.sqrt(np.mean((df_train['NUM_COLLISIONS'] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# Store RMSE for average\n",
        "rmse_avg = getattr(rmse, \"tolist\", lambda: rmse)()\n",
        "\n",
        "# Output success or failure message for this model\n",
        "if(rmse_DNN < rmse_avg): # If rmse is lower than average rmse\n",
        "  print('\\nGreat! Your DNN Regression model performs better than finding the average!'); # Success\n",
        "else: \n",
        "  print('\\nSorry! But on this run, your DNN Regression model performs worse than just finding the average!'); # Failure\n"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1b1eae6d8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_collision_regression_trained_model_combined_day_temps_percp', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_collision_regression_trained_model_combined_day_temps_percp/model.ckpt.\n",
            "INFO:tensorflow:loss = 7.8325915, step = 1\n",
            "INFO:tensorflow:global_step/sec: 490.311\n",
            "INFO:tensorflow:loss = 0.029052686, step = 101 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.545\n",
            "INFO:tensorflow:loss = 0.02826965, step = 201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.389\n",
            "INFO:tensorflow:loss = 0.018056884, step = 301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.867\n",
            "INFO:tensorflow:loss = 0.01758674, step = 401 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.969\n",
            "INFO:tensorflow:loss = 0.018937234, step = 501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.117\n",
            "INFO:tensorflow:loss = 0.017304424, step = 601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.775\n",
            "INFO:tensorflow:loss = 0.016528558, step = 701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.67\n",
            "INFO:tensorflow:loss = 0.023272408, step = 801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.028\n",
            "INFO:tensorflow:loss = 0.02191843, step = 901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.337\n",
            "INFO:tensorflow:loss = 0.023583215, step = 1001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.84\n",
            "INFO:tensorflow:loss = 0.015003622, step = 1101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.182\n",
            "INFO:tensorflow:loss = 0.025300644, step = 1201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.877\n",
            "INFO:tensorflow:loss = 0.019486718, step = 1301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.371\n",
            "INFO:tensorflow:loss = 0.012756249, step = 1401 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.092\n",
            "INFO:tensorflow:loss = 0.025860064, step = 1501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.397\n",
            "INFO:tensorflow:loss = 0.022542743, step = 1601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.928\n",
            "INFO:tensorflow:loss = 0.013869097, step = 1701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.663\n",
            "INFO:tensorflow:loss = 0.022943312, step = 1801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.445\n",
            "INFO:tensorflow:loss = 0.019642131, step = 1901 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.987\n",
            "INFO:tensorflow:loss = 0.021091733, step = 2001 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.325\n",
            "INFO:tensorflow:loss = 0.01913483, step = 2101 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.142\n",
            "INFO:tensorflow:loss = 0.017572356, step = 2201 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.808\n",
            "INFO:tensorflow:loss = 0.020104807, step = 2301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.693\n",
            "INFO:tensorflow:loss = 0.017504059, step = 2401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.253\n",
            "INFO:tensorflow:loss = 0.01917622, step = 2501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.215\n",
            "INFO:tensorflow:loss = 0.01981924, step = 2601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.424\n",
            "INFO:tensorflow:loss = 0.0136623345, step = 2701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.725\n",
            "INFO:tensorflow:loss = 0.016687874, step = 2801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.819\n",
            "INFO:tensorflow:loss = 0.022869967, step = 2901 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.416\n",
            "INFO:tensorflow:loss = 0.016110545, step = 3001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.348\n",
            "INFO:tensorflow:loss = 0.017347869, step = 3101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.21\n",
            "INFO:tensorflow:loss = 0.023098037, step = 3201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.438\n",
            "INFO:tensorflow:loss = 0.02125509, step = 3301 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.618\n",
            "INFO:tensorflow:loss = 0.0197822, step = 3401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.26\n",
            "INFO:tensorflow:loss = 0.01584819, step = 3501 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 711.326\n",
            "INFO:tensorflow:loss = 0.016717196, step = 3601 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.684\n",
            "INFO:tensorflow:loss = 0.022261025, step = 3701 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.941\n",
            "INFO:tensorflow:loss = 0.012870844, step = 3801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.39\n",
            "INFO:tensorflow:loss = 0.025774196, step = 3901 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.094\n",
            "INFO:tensorflow:loss = 0.0151110375, step = 4001 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.236\n",
            "INFO:tensorflow:loss = 0.017185533, step = 4101 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.491\n",
            "INFO:tensorflow:loss = 0.016647412, step = 4201 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.671\n",
            "INFO:tensorflow:loss = 0.020087313, step = 4301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.543\n",
            "INFO:tensorflow:loss = 0.016694166, step = 4401 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.255\n",
            "INFO:tensorflow:loss = 0.018452346, step = 4501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.557\n",
            "INFO:tensorflow:loss = 0.012907466, step = 4601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.105\n",
            "INFO:tensorflow:loss = 0.012938733, step = 4701 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.715\n",
            "INFO:tensorflow:loss = 0.01985465, step = 4801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.246\n",
            "INFO:tensorflow:loss = 0.015582344, step = 4901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.64\n",
            "INFO:tensorflow:loss = 0.015142791, step = 5001 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.602\n",
            "INFO:tensorflow:loss = 0.0198367, step = 5101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.833\n",
            "INFO:tensorflow:loss = 0.016441407, step = 5201 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.903\n",
            "INFO:tensorflow:loss = 0.016111419, step = 5301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.321\n",
            "INFO:tensorflow:loss = 0.014270004, step = 5401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.921\n",
            "INFO:tensorflow:loss = 0.014163251, step = 5501 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.502\n",
            "INFO:tensorflow:loss = 0.019275054, step = 5601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.422\n",
            "INFO:tensorflow:loss = 0.015632767, step = 5701 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.264\n",
            "INFO:tensorflow:loss = 0.018917035, step = 5801 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.432\n",
            "INFO:tensorflow:loss = 0.01850187, step = 5901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.703\n",
            "INFO:tensorflow:loss = 0.01233585, step = 6001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.803\n",
            "INFO:tensorflow:loss = 0.015414586, step = 6101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.522\n",
            "INFO:tensorflow:loss = 0.015299171, step = 6201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.245\n",
            "INFO:tensorflow:loss = 0.018348437, step = 6301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.477\n",
            "INFO:tensorflow:loss = 0.0144851, step = 6401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.915\n",
            "INFO:tensorflow:loss = 0.0150388535, step = 6501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.046\n",
            "INFO:tensorflow:loss = 0.012398948, step = 6601 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.503\n",
            "INFO:tensorflow:loss = 0.021844506, step = 6701 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.4\n",
            "INFO:tensorflow:loss = 0.013173202, step = 6801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.893\n",
            "INFO:tensorflow:loss = 0.015131459, step = 6901 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.38\n",
            "INFO:tensorflow:loss = 0.01410324, step = 7001 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.931\n",
            "INFO:tensorflow:loss = 0.013727045, step = 7101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.647\n",
            "INFO:tensorflow:loss = 0.01701407, step = 7201 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.993\n",
            "INFO:tensorflow:loss = 0.013763754, step = 7301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.373\n",
            "INFO:tensorflow:loss = 0.013666788, step = 7401 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.205\n",
            "INFO:tensorflow:loss = 0.017025398, step = 7501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.315\n",
            "INFO:tensorflow:loss = 0.015052686, step = 7601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.251\n",
            "INFO:tensorflow:loss = 0.015763162, step = 7701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.18\n",
            "INFO:tensorflow:loss = 0.01912297, step = 7801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.797\n",
            "INFO:tensorflow:loss = 0.017738232, step = 7901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.287\n",
            "INFO:tensorflow:loss = 0.015631841, step = 8001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.929\n",
            "INFO:tensorflow:loss = 0.01748696, step = 8101 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.141\n",
            "INFO:tensorflow:loss = 0.012409297, step = 8201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.694\n",
            "INFO:tensorflow:loss = 0.014260495, step = 8301 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.871\n",
            "INFO:tensorflow:loss = 0.018021163, step = 8401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.127\n",
            "INFO:tensorflow:loss = 0.012413093, step = 8501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.409\n",
            "INFO:tensorflow:loss = 0.017452106, step = 8601 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.478\n",
            "INFO:tensorflow:loss = 0.02175802, step = 8701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.97\n",
            "INFO:tensorflow:loss = 0.015759379, step = 8801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.939\n",
            "INFO:tensorflow:loss = 0.015500272, step = 8901 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.064\n",
            "INFO:tensorflow:loss = 0.019466236, step = 9001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.981\n",
            "INFO:tensorflow:loss = 0.01168007, step = 9101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.729\n",
            "INFO:tensorflow:loss = 0.014567434, step = 9201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.411\n",
            "INFO:tensorflow:loss = 0.01752069, step = 9301 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 675.569\n",
            "INFO:tensorflow:loss = 0.017083494, step = 9401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.766\n",
            "INFO:tensorflow:loss = 0.01832373, step = 9501 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.182\n",
            "INFO:tensorflow:loss = 0.018407805, step = 9601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.115\n",
            "INFO:tensorflow:loss = 0.019712094, step = 9701 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.336\n",
            "INFO:tensorflow:loss = 0.014765944, step = 9801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.724\n",
            "INFO:tensorflow:loss = 0.01497368, step = 9901 (0.157 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_collision_regression_trained_model_combined_day_temps_percp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.019644193.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_collision_regression_trained_model_combined_day_temps_percp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "DNNRegression has RMSE of 127.29511773466717\n",
            "Just using average = 564.1451398135819 has RMSE of 135.49527033063225\n",
            "\n",
            "Great! Your DNN Regression model performs better than finding the average!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YExNuvbDR22s"
      },
      "source": [
        "**5.2.1 Deep Neural Network Validation Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1I0W0SlR22s"
      },
      "source": [
        "# Perform validation assessment of DNN model using test values reserved from original dataset\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_collision_regression_trained_model_combined_day_temps_percp', hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_test.values)))\n",
        "\n",
        "# Use test values reserved from original data set\n",
        "preds = estimator.predict(x=predictors_test.values)\n",
        "predslistscale = preds['scores']*SCALE_NUM_COLLISIONS\n",
        "pred = format(str(predslistscale))\n",
        "print(\"\\n==== Predicted Number of Collisions ====\", pred)\n",
        "print(\"\\n==== Target Collision Values ====\", targets_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLBmvt_9R22t"
      },
      "source": [
        "From the results of the validation test, it can be seen that many of the predicted values are a very close match to the target values, although like previous models, the DNN models struggles to predict some of the higher target values, which were under-estimated by the DNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4npYagR22u"
      },
      "source": [
        "# **5.3 Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2WgrMm-R22u"
      },
      "source": [
        "By combining key data points from weather and date elements, which previously contributed to the generation of the better performing models, the resultant deep neural network model results consistently apears to provide a better than mean RMSE result.  The linear regression model also performed well, and generally produced a result superior to a mean value calculation.\r\n",
        "\r\n",
        "The DNN model in this case, could be a good candidate for use as a predictive tool for collision numbers and to inform emergency service planning in New York city."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnSnXfGZoqS"
      },
      "source": [
        "# **6. Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8uBdqDiZrRR"
      },
      "source": [
        "Through completion of both linear regression and Deep Neural Network Regressor models using different data sets and data selections, the potential to predict the number of collisions for New York City can be summarised as follows:  \r\n",
        "\r\n",
        "**Linear Regression Models**\r\n",
        "\r\n",
        "Through examination of the results of each model, it was found that in most cases, a linear regression model alone had mostly unsatisfactory results.  In many cases the performance of the linear regression model was heavily dependent on the specific rows of data selected and used to train the model, and there appears to be no combination of linear regression data selection which results in a consistently reliable predictive ability for the number of collisions.\r\n",
        "\r\n",
        "It was surprising to see that depending on how the data was shuffled, the results of linear regression modelling could produce better results than the average calculation, but this was inconsistent and unreliable, and statistically rarely better than a mean average.\r\n",
        "\r\n",
        "I suspect the relatively poor performance of linear regression in this case, may be due to the fact that the data sets available do not necessarily include all of the data required to make such a prediction.  In reality, there are multiple, complex and chaotic contributing factors responsible in causing a collision to take place on a particular day or location, and without including all the factors, including the human factors, any linear regression model used as a predictive model, will be potentially inadequate for consistent and detailed forecasting. \r\n",
        "\r\n",
        "\r\n",
        "**Deep Neural Network Models**\r\n",
        "\r\n",
        "Compared to the linear regression models, the deep neural network (DNN) models seemed to perform consistently better overall, and in particular, when applied to data related to temperature and precipitation factors in combination with day and month data.  Like the linear regression models, it was clear that the performance of the DNN models relied heavily on the particular training data it was supplied, which was an over-simplification of all the complex contributing factors to the cause of many collisions. \r\n",
        "\r\n",
        "**Summary**\r\n",
        "\r\n",
        "Overall, DNN models did perform better than linear regression for most data selected, and I would recommend to the emergency services of New York City the use of the DNN model which used *Month, Day, Mean Temperature, Max Temp, Min Temp and Precipitation data*, as during testing, this combination resulted in the most consistent, better than mean, predictive ability for the number of traffic collisions per day.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}